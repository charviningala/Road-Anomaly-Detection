{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c2e6f98",
   "metadata": {},
   "source": [
    "# Yolov26s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69cac611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.5.1+cu121 CPU (13th Gen Intel Core i7-13620H)\n",
      "YOLO26s summary (fused): 122 layers, 9,465,954 parameters, 0 gradients, 20.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (19.4 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1771429876.131695  130423 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1771429876.143205  130423 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1771429876.245621  130423 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771429876.245634  130423 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771429876.245635  130423 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771429876.245636  130423 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=/home/saber/GitHub/road_anomaly_detection/data/calibr_yaml/data.yaml'\n",
      "Fast image access ‚úÖ (ping: 0.1¬±0.1 ms, read: 488.1¬±106.4 MB/s, size: 128.3 KB)\n",
      "\u001b[KScanning /home/saber/GitHub/road_anomaly_detection/data/calibration_images.cache... 0 images, 300 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 300/300 125.8Mit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è Labels are missing or empty in /home/saber/GitHub/road_anomaly_detection/data/calibration_images.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saber/GitHub/road_anomaly_detection/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:5385: UserWarning: Exporting aten::index operator of advanced indexing in opset 19 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.84...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.1s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best.onnx' (36.5 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.8...\n",
      "Saved artifact at '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serving_default'\n",
      "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(1, 300, 6), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  139930275721488: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139930275719760: TensorSpec(shape=(3, 3, 3, 32), dtype=tf.float32, name=None)\n",
      "  139930275722448: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139930275725136: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139930275724368: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
      "  139930279756624: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930275722640: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930279757008: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930279757392: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279756816: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930275717456: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n",
      "  139930275717072: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  139930279758736: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
      "  139930279758544: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139930279757200: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279757584: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279757968: TensorSpec(shape=(1, 1, 96, 128), dtype=tf.float32, name=None)\n",
      "  139930279758160: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930279758928: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139930279759312: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  139930279759696: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930279760080: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  139930279760272: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930279760848: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279760656: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279762768: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n",
      "  139930279762960: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139930279760464: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
      "  139930279759888: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930279761040: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279761232: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279763152: TensorSpec(shape=(1, 1, 192, 256), dtype=tf.float32, name=None)\n",
      "  139930279761808: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930279763536: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139930279762192: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  139930279763344: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930279763728: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  139930279763920: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930279764496: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279764304: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279766416: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  139930279766608: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930279765840: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930279766800: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930279766992: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930279767184: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930279766032: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930279767568: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930279765456: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930279762384: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  139930279767760: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930279764112: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930279768336: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  139930279767376: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930279764688: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279764880: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279768528: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  139930279768720: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930279768912: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139930279767952: TensorSpec(shape=(3, 3, 256, 512), dtype=tf.float32, name=None)\n",
      "  139930279768144: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  139930279769296: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
      "  139930279769488: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  139930279770064: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279769872: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279771984: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  139930279771792: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930279771408: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  139930279771600: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930279771024: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  139930212122896: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930212123280: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  139930212123664: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930212123088: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  139930279769104: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  139930212123856: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930279769680: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930212124432: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  139930212123472: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930279770256: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930279770448: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930212124624: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
      "  139930212124816: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  139930212124048: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
      "  139930212125008: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930212125200: TensorSpec(shape=(1, 1, 1024, 512), dtype=tf.float32, name=None)\n",
      "  139930212124240: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  139930212125392: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
      "  139930212125968: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  139930212125776: TensorSpec(shape=(1, 1, 256, 512), dtype=tf.float32, name=None)\n",
      "  139930212126544: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  139930212127696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139930212126352: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930212132112: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  139930212131344: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930212126736: TensorSpec(shape=(1, 1, 256, 512), dtype=tf.float32, name=None)\n",
      "  139930212128848: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  139930212132496: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
      "  139930212132880: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930212127888: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
      "  139930212131728: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  139930212130192: TensorSpec(shape=(1, 1, 768, 256), dtype=tf.float32, name=None)\n",
      "  139930212132304: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930212131920: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930212131536: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930212134608: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  139930212134800: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930212134032: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930212134992: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930212135184: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930212135376: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930212134224: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930212135760: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930212133648: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930212130960: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  139930212135952: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930212131152: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930212136528: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  139930212135568: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930212132688: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930212133072: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930212136720: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  139930212136912: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930212137296: TensorSpec(shape=(1, 1, 512, 128), dtype=tf.float32, name=None)\n",
      "  139930212136144: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930212137680: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930212137488: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930212137104: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
      "  139930212138640: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139930212138256: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139930042664144: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139930042663184: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139930042663952: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139930042664336: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139930042664720: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139930042663760: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139930212138448: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
      "  139930042664912: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139930212136336: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139930042665488: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930042664528: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930212137872: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930212138064: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930042665680: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  139930042665872: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930042666064: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139930042665104: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  139930042665296: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930042668176: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  139930042667600: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930042669136: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930042669328: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930042670480: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  139930042672592: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930042670864: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930042671632: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930042673168: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930042673552: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930042672784: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930042674512: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930042672976: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139930042672016: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  139930042673744: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930042669520: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139930042673360: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  139930042671056: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930042669712: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930042669904: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930042674704: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  139930042673936: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930042674128: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139930042672400: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  139930042674896: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930042676816: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
      "  139930042676240: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  139930042677776: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930042677968: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930042679120: TensorSpec(shape=(3, 3, 256, 128), dtype=tf.float32, name=None)\n",
      "  139930042678160: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930042677008: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
      "  139929932973456: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139929932973648: TensorSpec(shape=(1, 1, 256, 512), dtype=tf.float32, name=None)\n",
      "  139929932974224: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  139929932975184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139929932975760: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139929932976336: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  139929932977104: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139929932975568: TensorSpec(shape=(1, 1, 256, 512), dtype=tf.float32, name=None)\n",
      "  139929932975376: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  139929932976912: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
      "  139929932974800: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930042678352: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139930042678544: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139929932974992: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
      "  139929932976144: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  139929932974608: TensorSpec(shape=(3, 3, 512, 1), dtype=tf.float32, name=None)\n",
      "  139930042675472: TensorSpec(shape=(3, 3, 256, 1), dtype=tf.float32, name=None)\n",
      "  139930042666832: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
      "  139929932973840: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  139930042675664: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139930042667024: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139929932977488: TensorSpec(shape=(1, 1, 512, 128), dtype=tf.float32, name=None)\n",
      "  139930042676432: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  139930042667792: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  139929932973072: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930042674320: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930042666256: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139929932976720: TensorSpec(shape=(3, 3, 512, 32), dtype=tf.float32, name=None)\n",
      "  139930042675280: TensorSpec(shape=(3, 3, 256, 32), dtype=tf.float32, name=None)\n",
      "  139930042666640: TensorSpec(shape=(3, 3, 128, 32), dtype=tf.float32, name=None)\n",
      "  139929932975952: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139930042675088: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139930042666448: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139929932976528: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
      "  139930042677392: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
      "  139930042668752: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
      "  139929932978256: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930042677584: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930042668944: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139929932972496: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139930042676048: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139930042667408: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139929932977296: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139930042675856: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139930042667216: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139929932979024: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  139930042678928: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  139930042671824: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  139929932977872: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930042678736: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139930042668368: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139929932977680: TensorSpec(shape=(1, 1, 32, 4), dtype=tf.float32, name=None)\n",
      "  139930042677200: TensorSpec(shape=(1, 1, 32, 4), dtype=tf.float32, name=None)\n",
      "  139930042668560: TensorSpec(shape=(1, 1, 32, 4), dtype=tf.float32, name=None)\n",
      "  139929932978064: TensorSpec(shape=(4,), dtype=tf.float32, name=None)\n",
      "  139930042676624: TensorSpec(shape=(4,), dtype=tf.float32, name=None)\n",
      "  139930042667984: TensorSpec(shape=(4,), dtype=tf.float32, name=None)\n",
      "  139929932979216: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
      "  139929932973264: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
      "  139930042671440: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
      "  139929932981520: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  139929932974032: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  139930042672208: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  139929932978832: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139929932980752: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139929932979600: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139929932979408: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139929932979792: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
      "  139929932981328: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
      "  139929932983632: TensorSpec(shape=(), dtype=tf.int64, name=None)\n",
      "  139929932981904: TensorSpec(shape=(2, 1), dtype=tf.int32, name=None)\n",
      "  139929932983248: TensorSpec(shape=(2,), dtype=tf.int32, name=None)\n",
      "  139929932986320: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
      "  139929932984208: TensorSpec(shape=(), dtype=tf.int64, name=None)\n",
      "  139929932988240: TensorSpec(shape=(2, 1), dtype=tf.int32, name=None)\n",
      "  139929932982096: TensorSpec(shape=(2,), dtype=tf.int32, name=None)\n",
      "  139929932982864: TensorSpec(shape=(), dtype=tf.int64, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1771429906.723055  130423 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1771429906.723128  130423 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1771429907.408935  130423 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771429907.408948  130423 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1771429908.190929  130423 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1771429908.191019  130423 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1771429908.746588  130423 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771429908.746601  130423 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1771429909.619678  130423 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1771429909.619749  130423 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1771429910.174497  130423 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771429910.174509  130423 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1771429913.164213  130423 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771429913.164224  130423 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1771429913.202776  130423 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "W0000 00:00:1771430300.143969  130423 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771430300.145128  130423 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "W0000 00:00:1771430688.112644  130423 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771430688.112655  130423 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "W0000 00:00:1771431456.789605  130423 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771431456.789615  130423 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 2353.7s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model' (120.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ‚úÖ 0.0s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_int8.tflite' (9.6 MB)\n",
      "\n",
      "Export complete (2354.1s)\n",
      "Results saved to \u001b[1m/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_int8.tflite imgsz=640 int8\n",
      "Validate:        yolo val task=detect model=/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_int8.tflite imgsz=640 data=/home/saber/GitHub/road_anomaly_detection/data/rdd2class_yolo/rdd2class.yaml int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_int8.tflite'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best.pt\")\n",
    "\n",
    "model.export(\n",
    "    format=\"tflite\",\n",
    "    int8=True,\n",
    "    data=\"/home/saber/GitHub/road_anomaly_detection/data/calibr_yaml/data.yaml\",   # important\n",
    "    imgsz=640\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a62ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.5.1+cu121 CPU (13th Gen Intel Core i7-13620H)\n",
      "Loading /home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_int8.tflite for TensorFlow Lite inference...\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2896.0¬±1542.1 MB/s, size: 121.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/saber/GitHub/road_anomaly_detection/data/rdd2class_yolo/labels/val.cache... 5120 images, 1670 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5120/5120 127.1Mit/s 0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5120/5120 9.1it/s 9:25<0.1s\n",
      "                   all       5120       7177       0.76      0.709      0.769      0.452\n",
      "                 crack       3205       6116      0.757      0.763      0.808      0.485\n",
      "               pothole        644       1061      0.764      0.655      0.731      0.418\n",
      "Speed: 0.3ms preprocess, 106.4ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1m/home/saber/GitHub/road_anomaly_detection/runs/detect/val11\u001b[0m\n",
      "0.45167904045120066\n",
      "0.7693250920546977\n",
      "0.7603900795594507\n",
      "0.7088161704378251\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_int8.tflite\")\n",
    "\n",
    "metrics = model.val(\n",
    "    data=\"/home/saber/GitHub/road_anomaly_detection/data/rdd2class_yolo/rdd2class.yaml\",\n",
    "    imgsz=640\n",
    ")\n",
    "\n",
    "print(metrics.box.map)      # mAP50-95\n",
    "print(metrics.box.map50)    # mAP50\n",
    "print(metrics.box.mp)       # Precision\n",
    "print(metrics.box.mr)       # Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f35d0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7336979191767559\n"
     ]
    }
   ],
   "source": [
    "precision = metrics.box.mp\n",
    "recall = metrics.box.mr\n",
    "\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "680de3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TFLite model...\n",
      "Input dtype: <class 'numpy.float32'>\n",
      "Input quantization: (0.0, 0)\n",
      "\n",
      "Running inference benchmark...\n",
      "\n",
      "========== RESULTS ==========\n",
      "Frames measured : 280\n",
      "Avg latency     : 100.56 ms\n",
      "Avg FPS         : 9.94\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# CONFIG\n",
    "TFLITE_MODEL = \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_int8.tflite\"\n",
    "VIDEO_PATH = \"/home/saber/GitHub/road_anomaly_detection/data/videos/3695999-hd_1920_1080_24fps.mp4\"\n",
    "IMG_SIZE = 640\n",
    "NUM_WARMUP = 20\n",
    "MAX_FRAMES = 300\n",
    "\n",
    "print(\"Loading TFLite model...\")\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input dtype:\", input_details[0][\"dtype\"])\n",
    "print(\"Input quantization:\", input_details[0][\"quantization\"])\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "assert cap.isOpened(), \"Could not open video\"\n",
    "\n",
    "frame_count = 0\n",
    "timings = []\n",
    "\n",
    "print(\"\\nRunning inference benchmark...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count > MAX_FRAMES:\n",
    "        break\n",
    "\n",
    "    # Preprocess\n",
    "    img = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)   # Keep FLOAT32\n",
    "\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], img)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    interpreter.invoke()\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    if frame_count > NUM_WARMUP:\n",
    "        timings.append(end - start)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# RESULTS\n",
    "total_frames = len(timings)\n",
    "avg_time = sum(timings) / total_frames\n",
    "avg_fps = 1.0 / avg_time\n",
    "\n",
    "print(\"\\n========== RESULTS ==========\")\n",
    "print(f\"Frames measured : {total_frames}\")\n",
    "print(f\"Avg latency     : {avg_time*1000:.2f} ms\")\n",
    "print(f\"Avg FPS         : {avg_fps:.2f}\")\n",
    "print(\"================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8682f995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.5.1+cu121 CPU (13th Gen Intel Core i7-13620H)\n",
      "Loading /home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_full_integer_quant.tflite for TensorFlow Lite inference...\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 5302.1¬±2063.7 MB/s, size: 124.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/saber/GitHub/road_anomaly_detection/data/rdd2class_yolo/labels/val.cache... 5120 images, 1670 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5120/5120 3.1Git/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5120/5120 11.0it/s 7:45<0.1s\n",
      "                   all       5120       7177      0.372      0.224      0.279      0.152\n",
      "                 crack       3205       6116      0.745      0.448      0.559      0.305\n",
      "               pothole        644       1061          0          0          0          0\n",
      "Speed: 0.3ms preprocess, 87.3ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1m/home/saber/GitHub/road_anomaly_detection/runs/detect/val12\u001b[0m\n",
      "0.15233174026785504\n",
      "0.2794877539056313\n",
      "0.3722584396433536\n",
      "0.2239208633093525\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_full_integer_quant.tflite\")\n",
    "\n",
    "metrics = model.val(\n",
    "    data=\"/home/saber/GitHub/road_anomaly_detection/data/rdd2class_yolo/rdd2class.yaml\",\n",
    "    imgsz=640\n",
    ")\n",
    "\n",
    "print(metrics.box.map)      # mAP50-95\n",
    "print(metrics.box.map50)    # mAP50\n",
    "print(metrics.box.mp)       # Precision\n",
    "print(metrics.box.mr)       # Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53a32d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.2796354411040155\n"
     ]
    }
   ],
   "source": [
    "precision = metrics.box.mp\n",
    "recall = metrics.box.mr\n",
    "\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b33cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a127c802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂ Loading TFLite INT8 model...\n",
      "Input dtype : <class 'numpy.int8'>\n",
      "Output dtype: <class 'numpy.int8'>\n",
      "Input quant : (0.003921568859368563, -128)\n",
      "Output quant: (0.005234360229223967, -104)\n",
      "FPS detected: 24.0\n",
      "\n",
      "‚ñ∂ Running inference + saving AVI output...\n",
      "\n",
      "========== RESULTS ==========\n",
      "Frames measured : 280\n",
      "Avg latency     : 43.47 ms\n",
      "Avg FPS         : 23.01\n",
      "Saved video     : ../../../runs/tflite/output_predictions.avi\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# ================= CONFIG =================\n",
    "TFLITE_MODEL = \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_full_integer_quant.tflite\"\n",
    "VIDEO_PATH = \"/home/saber/GitHub/road_anomaly_detection/data/videos/3695999-hd_1920_1080_24fps.mp4\"\n",
    "OUTPUT_VIDEO = \"../../../runs/tflite/output_predictions.avi\"   # <-- AVI now\n",
    "\n",
    "MODEL_IMG_SIZE = 640\n",
    "VIDEO_DECODE_WIDTH = 960\n",
    "VIDEO_DECODE_HEIGHT = 540\n",
    "\n",
    "CONF_THRESH = 0.25\n",
    "NUM_WARMUP = 20\n",
    "MAX_FRAMES = 300\n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: \"Road Defect\",\n",
    "    1: \"Pothole\"\n",
    "}\n",
    "\n",
    "# ================= LOAD MODEL =================\n",
    "print(\"‚ñ∂ Loading TFLite INT8 model...\")\n",
    "\n",
    "interpreter = tf.lite.Interpreter(\n",
    "    model_path=TFLITE_MODEL,\n",
    "    num_threads=4\n",
    ")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input dtype :\", input_details[0][\"dtype\"])\n",
    "print(\"Output dtype:\", output_details[0][\"dtype\"])\n",
    "print(\"Input quant :\", input_details[0][\"quantization\"])\n",
    "print(\"Output quant:\", output_details[0][\"quantization\"])\n",
    "\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "output_scale, output_zero_point = output_details[0][\"quantization\"]\n",
    "\n",
    "# ================= VIDEO SETUP =================\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "assert cap.isOpened(), \"Could not open video\"\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, VIDEO_DECODE_WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, VIDEO_DECODE_HEIGHT)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"FPS detected:\", fps)\n",
    "\n",
    "\n",
    "# AVI with MJPG codec\n",
    "writer = cv2.VideoWriter(\n",
    "    OUTPUT_VIDEO,\n",
    "    cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
    "    fps if fps > 0 else 24,  # fallback FPS\n",
    "    (VIDEO_DECODE_WIDTH, VIDEO_DECODE_HEIGHT)\n",
    ")\n",
    "\n",
    "if not writer.isOpened():\n",
    "    print(\"VideoWriter failed to open!\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "frame_count = 0\n",
    "timings = []\n",
    "\n",
    "print(\"\\n‚ñ∂ Running inference + saving AVI output...\")\n",
    "\n",
    "# ================= INFERENCE LOOP =================\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count > MAX_FRAMES:\n",
    "        break\n",
    "\n",
    "    orig_h, orig_w = frame.shape[:2]\n",
    "\n",
    "    # ---------- PREPROCESS ----------\n",
    "    img = cv2.resize(frame, (MODEL_IMG_SIZE, MODEL_IMG_SIZE))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "\n",
    "    img = img / input_scale + input_zero_point\n",
    "    img = np.clip(img, -128, 127).astype(np.int8)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], img)\n",
    "\n",
    "    # ---------- INFERENCE ----------\n",
    "    start = time.perf_counter()\n",
    "    interpreter.invoke()\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    if frame_count > NUM_WARMUP:\n",
    "        timings.append(end - start)\n",
    "\n",
    "    # ---------- POSTPROCESS ----------\n",
    "    output = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    output = (output.astype(np.float32) - output_zero_point) * output_scale\n",
    "    output = output[0]\n",
    "\n",
    "    for det in output:\n",
    "        if len(det) < 6:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2, score, cls = det[:6]\n",
    "\n",
    "        if score < CONF_THRESH:\n",
    "            continue\n",
    "\n",
    "        cls = int(cls)\n",
    "\n",
    "        x1 = int(x1 * orig_w / MODEL_IMG_SIZE)\n",
    "        x2 = int(x2 * orig_w / MODEL_IMG_SIZE)\n",
    "        y1 = int(y1 * orig_h / MODEL_IMG_SIZE)\n",
    "        y2 = int(y2 * orig_h / MODEL_IMG_SIZE)\n",
    "\n",
    "        x1 = max(0, min(orig_w, x1))\n",
    "        x2 = max(0, min(orig_w, x2))\n",
    "        y1 = max(0, min(orig_h, y1))\n",
    "        y2 = max(0, min(orig_h, y2))\n",
    "\n",
    "        label = f\"{CLASS_NAMES.get(cls, 'Unknown')} {score:.2f}\"\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            label,\n",
    "            (x1, max(20, y1 - 5)),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    writer.write(frame)\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "# ================= RESULTS =================\n",
    "if len(timings) > 0:\n",
    "    avg_time = sum(timings) / len(timings)\n",
    "    avg_fps = 1.0 / avg_time\n",
    "\n",
    "    print(\"\\n========== RESULTS ==========\")\n",
    "    print(f\"Frames measured : {len(timings)}\")\n",
    "    print(f\"Avg latency     : {avg_time*1000:.2f} ms\")\n",
    "    print(f\"Avg FPS         : {avg_fps:.2f}\")\n",
    "else:\n",
    "    print(\"Not enough frames for timing.\")\n",
    "\n",
    "print(f\"Saved video     : {OUTPUT_VIDEO}\")\n",
    "print(\"================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf0bc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂ Loading YOLOv26 INT8 model...\n",
      "Input dtype : <class 'numpy.int8'>\n",
      "Output dtype: <class 'numpy.int8'>\n",
      "‚ñ∂ Resolution: 1920x1080, FPS: 24.0\n",
      "\n",
      "========== RESULTS ==========\n",
      "Frames processed           : 301\n",
      "Avg FPS (model)            : 23.57\n",
      "Output file                : ../../../runs/tflite/output_predictions.avi\n",
      "File size (MB)             : 41.05\n",
      "\n",
      "========== DETECTION STATS ==========\n",
      "Total detections           : 60\n",
      "Frames with detections     : 48\n",
      "Max confidence observed    : 0.957888\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# ================= CONFIG =================\n",
    "TFLITE_MODEL = \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_full_integer_quant.tflite\"\n",
    "VIDEO_PATH = \"/home/saber/GitHub/road_anomaly_detection/data/videos/3695999-hd_1920_1080_24fps.mp4\"\n",
    "OUTPUT_VIDEO = \"../../../runs/tflite/output_predictions.avi\"\n",
    "\n",
    "MODEL_IMG_SIZE = 640\n",
    "CONF_THRESH = 0.01\n",
    "NUM_WARMUP = 20\n",
    "MAX_FRAMES = 300\n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: \"Road Defect\",\n",
    "    1: \"Pothole\"\n",
    "}\n",
    "\n",
    "# ================= LETTERBOX =================\n",
    "def letterbox(img, new_shape=640):\n",
    "    shape = img.shape[:2]\n",
    "    r = min(new_shape / shape[0], new_shape / shape[1])\n",
    "\n",
    "    new_unpad = (int(round(shape[1] * r)),\n",
    "                 int(round(shape[0] * r)))\n",
    "\n",
    "    img_resized = cv2.resize(img, new_unpad,\n",
    "                             interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    dw = new_shape - new_unpad[0]\n",
    "    dh = new_shape - new_unpad[1]\n",
    "    dw /= 2\n",
    "    dh /= 2\n",
    "\n",
    "    top = int(round(dh - 0.1))\n",
    "    bottom = int(round(dh + 0.1))\n",
    "    left = int(round(dw - 0.1))\n",
    "    right = int(round(dw + 0.1))\n",
    "\n",
    "    img_padded = cv2.copyMakeBorder(\n",
    "        img_resized,\n",
    "        top, bottom, left, right,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=(114, 114, 114)\n",
    "    )\n",
    "\n",
    "    return img_padded, r, dw, dh\n",
    "\n",
    "# ================= LOAD MODEL =================\n",
    "print(\"‚ñ∂ Loading YOLOv26 INT8 model...\")\n",
    "\n",
    "interpreter = tf.lite.Interpreter(\n",
    "    model_path=TFLITE_MODEL,\n",
    "    num_threads=4\n",
    ")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_scale, input_zero = input_details[0][\"quantization\"]\n",
    "output_scale, output_zero = output_details[0][\"quantization\"]\n",
    "\n",
    "print(\"Input dtype :\", input_details[0][\"dtype\"])\n",
    "print(\"Output dtype:\", output_details[0][\"dtype\"])\n",
    "\n",
    "# ================= VIDEO SETUP =================\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "assert cap.isOpened(), \"‚ùå Could not open video\"\n",
    "\n",
    "ret, first_frame = cap.read()\n",
    "assert ret, \"‚ùå Could not read first frame\"\n",
    "\n",
    "FRAME_H, FRAME_W = first_frame.shape[:2]\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if fps == 0 or np.isnan(fps):\n",
    "    fps = 24\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_VIDEO), exist_ok=True)\n",
    "\n",
    "writer = cv2.VideoWriter(\n",
    "    OUTPUT_VIDEO,\n",
    "    cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "    fps,\n",
    "    (FRAME_W, FRAME_H)\n",
    ")\n",
    "\n",
    "assert writer.isOpened(), \"‚ùå VideoWriter failed\"\n",
    "\n",
    "print(f\"‚ñ∂ Resolution: {FRAME_W}x{FRAME_H}, FPS: {fps}\")\n",
    "\n",
    "# ================= COUNTERS =================\n",
    "frame_count = 0\n",
    "timings = []\n",
    "\n",
    "total_detections = 0\n",
    "frames_with_detections = 0\n",
    "max_conf_seen = 0.0\n",
    "\n",
    "# ================= INFERENCE LOOP =================\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count > MAX_FRAMES:\n",
    "        break\n",
    "\n",
    "    orig_h, orig_w = frame.shape[:2]\n",
    "\n",
    "    # ---------- PREPROCESS ----------\n",
    "    img, r, dw, dh = letterbox(frame, MODEL_IMG_SIZE)\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "\n",
    "    img = img / input_scale + input_zero\n",
    "    img = np.clip(img, -128, 127).astype(np.int8)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], img)\n",
    "\n",
    "    # ---------- INFERENCE ----------\n",
    "    start = time.perf_counter()\n",
    "    interpreter.invoke()\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    if frame_count > NUM_WARMUP:\n",
    "        timings.append(end - start)\n",
    "\n",
    "    # ---------- POSTPROCESS ----------\n",
    "    output = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    output = (output.astype(np.float32) - output_zero) * output_scale\n",
    "    output = output[0]\n",
    "\n",
    "    frame_detections = 0\n",
    "\n",
    "    for det in output:\n",
    "        if len(det) < 6:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2, conf, cls = det[:6]\n",
    "\n",
    "        # Track maximum confidence seen\n",
    "        if conf > max_conf_seen:\n",
    "            max_conf_seen = conf\n",
    "\n",
    "        if conf < CONF_THRESH:\n",
    "            continue\n",
    "\n",
    "        frame_detections += 1\n",
    "        total_detections += 1\n",
    "\n",
    "        cls = int(cls)\n",
    "\n",
    "        # Undo letterbox\n",
    "        x1 = (x1 - dw) / r\n",
    "        y1 = (y1 - dh) / r\n",
    "        x2 = (x2 - dw) / r\n",
    "        y2 = (y2 - dh) / r\n",
    "\n",
    "        x1 = int(max(0, min(x1, orig_w - 1)))\n",
    "        y1 = int(max(0, min(y1, orig_h - 1)))\n",
    "        x2 = int(max(0, min(x2, orig_w - 1)))\n",
    "        y2 = int(max(0, min(y2, orig_h - 1)))\n",
    "\n",
    "        label = f\"{CLASS_NAMES.get(cls,'Unknown')} {conf:.2f}\"\n",
    "\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "        cv2.putText(frame, label,\n",
    "                    (x1, max(20,y1-5)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (0,255,0), 2)\n",
    "\n",
    "    if frame_detections > 0:\n",
    "        frames_with_detections += 1\n",
    "\n",
    "    writer.write(frame)\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "# ================= RESULTS =================\n",
    "if timings:\n",
    "    avg_time = sum(timings) / len(timings)\n",
    "    avg_fps = 1.0 / avg_time\n",
    "else:\n",
    "    avg_fps = 0.0\n",
    "\n",
    "print(\"\\n========== RESULTS ==========\")\n",
    "print(f\"Frames processed           : {frame_count}\")\n",
    "print(f\"Avg FPS (model)            : {avg_fps:.2f}\")\n",
    "print(f\"Output file                : {OUTPUT_VIDEO}\")\n",
    "print(f\"File size (MB)             : {os.path.getsize(OUTPUT_VIDEO)/1e6:.2f}\")\n",
    "\n",
    "print(\"\\n========== DETECTION STATS ==========\")\n",
    "print(f\"Total detections           : {total_detections}\")\n",
    "print(f\"Frames with detections     : {frames_with_detections}\")\n",
    "print(f\"Max confidence observed    : {max_conf_seen:.6f}\")\n",
    "print(\"======================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2839e59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂ Loading YOLOv26 INT8 model...\n",
      "Input dtype : <class 'numpy.int8'>\n",
      "Output dtype: <class 'numpy.int8'>\n",
      "‚ñ∂ Resolution: 1920x1080, FPS: 24.0\n",
      "\n",
      "========== RESULTS ==========\n",
      "Frames processed           : 301\n",
      "Avg FPS (model)            : 23.26\n",
      "Output file                : ../../../runs/tflite/output_predictions.avi\n",
      "File size (MB)             : 41.05\n",
      "\n",
      "========== DETECTION STATS ==========\n",
      "Total detections           : 60\n",
      "Frames with detections     : 48\n",
      "Max confidence observed    : 0.957888\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# ================= CONFIG =================\n",
    "TFLITE_MODEL = \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_full_integer_quant.tflite\"\n",
    "VIDEO_PATH = \"/home/saber/GitHub/road_anomaly_detection/data/videos/3695999-hd_1920_1080_24fps.mp4\"\n",
    "OUTPUT_VIDEO = \"../../../runs/tflite/output_predictions.avi\"\n",
    "\n",
    "MODEL_IMG_SIZE = 640\n",
    "CONF_THRESH = 0.01\n",
    "NUM_WARMUP = 20\n",
    "MAX_FRAMES = 300\n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: \"Road Defect\",\n",
    "    1: \"Pothole\"\n",
    "}\n",
    "\n",
    "# ================= LETTERBOX =================\n",
    "def letterbox(img, new_shape=640):\n",
    "    shape = img.shape[:2]\n",
    "    r = min(new_shape / shape[0], new_shape / shape[1])\n",
    "\n",
    "    new_unpad = (int(round(shape[1] * r)),\n",
    "                 int(round(shape[0] * r)))\n",
    "\n",
    "    img_resized = cv2.resize(img, new_unpad,\n",
    "                             interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    dw = new_shape - new_unpad[0]\n",
    "    dh = new_shape - new_unpad[1]\n",
    "    dw /= 2\n",
    "    dh /= 2\n",
    "\n",
    "    top = int(round(dh - 0.1))\n",
    "    bottom = int(round(dh + 0.1))\n",
    "    left = int(round(dw - 0.1))\n",
    "    right = int(round(dw + 0.1))\n",
    "\n",
    "    img_padded = cv2.copyMakeBorder(\n",
    "        img_resized,\n",
    "        top, bottom, left, right,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=(114, 114, 114)\n",
    "    )\n",
    "\n",
    "    return img_padded, r, dw, dh\n",
    "\n",
    "# ================= LOAD MODEL =================\n",
    "print(\"‚ñ∂ Loading YOLOv26 INT8 model...\")\n",
    "\n",
    "interpreter = tf.lite.Interpreter(\n",
    "    model_path=TFLITE_MODEL,\n",
    "    num_threads=4\n",
    ")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_scale, input_zero = input_details[0][\"quantization\"]\n",
    "output_scale, output_zero = output_details[0][\"quantization\"]\n",
    "\n",
    "print(\"Input dtype :\", input_details[0][\"dtype\"])\n",
    "print(\"Output dtype:\", output_details[0][\"dtype\"])\n",
    "\n",
    "# ================= VIDEO SETUP =================\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "assert cap.isOpened(), \"‚ùå Could not open video\"\n",
    "\n",
    "ret, first_frame = cap.read()\n",
    "assert ret, \"‚ùå Could not read first frame\"\n",
    "\n",
    "FRAME_H, FRAME_W = first_frame.shape[:2]\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if fps == 0 or np.isnan(fps):\n",
    "    fps = 24\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_VIDEO), exist_ok=True)\n",
    "\n",
    "writer = cv2.VideoWriter(\n",
    "    OUTPUT_VIDEO,\n",
    "    cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "    fps,\n",
    "    (FRAME_W, FRAME_H)\n",
    ")\n",
    "\n",
    "assert writer.isOpened(), \"‚ùå VideoWriter failed\"\n",
    "\n",
    "print(f\"‚ñ∂ Resolution: {FRAME_W}x{FRAME_H}, FPS: {fps}\")\n",
    "\n",
    "# ================= COUNTERS =================\n",
    "frame_count = 0\n",
    "timings = []\n",
    "\n",
    "total_detections = 0\n",
    "frames_with_detections = 0\n",
    "max_conf_seen = 0.0\n",
    "\n",
    "# ================= INFERENCE LOOP =================\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count > MAX_FRAMES:\n",
    "        break\n",
    "\n",
    "    orig_h, orig_w = frame.shape[:2]\n",
    "\n",
    "    # ---------- PREPROCESS ----------\n",
    "    img, r, dw, dh = letterbox(frame, MODEL_IMG_SIZE)\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "\n",
    "    img = img / input_scale + input_zero\n",
    "    img = np.clip(img, -128, 127).astype(np.int8)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], img)\n",
    "\n",
    "    # ---------- INFERENCE ----------\n",
    "    start = time.perf_counter()\n",
    "    interpreter.invoke()\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    if frame_count > NUM_WARMUP:\n",
    "        timings.append(end - start)\n",
    "\n",
    "    # ---------- POSTPROCESS ----------\n",
    "    output = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    output = (output.astype(np.float32) - output_zero) * output_scale\n",
    "    output = output[0]\n",
    "\n",
    "    frame_detections = 0\n",
    "\n",
    "    for det in output:\n",
    "        if len(det) < 6:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2, conf, cls = det[:6]\n",
    "\n",
    "        # Track maximum confidence seen\n",
    "        if conf > max_conf_seen:\n",
    "            max_conf_seen = conf\n",
    "\n",
    "        if conf < CONF_THRESH:\n",
    "            continue\n",
    "\n",
    "        frame_detections += 1\n",
    "        total_detections += 1\n",
    "\n",
    "        cls = int(cls)\n",
    "\n",
    "        # Undo letterbox\n",
    "        x1 = x1 * orig_w / MODEL_IMG_SIZE\n",
    "        y1 = y1 * orig_h / MODEL_IMG_SIZE\n",
    "        x2 = x2 * orig_w / MODEL_IMG_SIZE\n",
    "        y2 = y2 * orig_h / MODEL_IMG_SIZE\n",
    "\n",
    "\n",
    "        x1 = int(max(0, min(x1, orig_w - 1)))\n",
    "        y1 = int(max(0, min(y1, orig_h - 1)))\n",
    "        x2 = int(max(0, min(x2, orig_w - 1)))\n",
    "        y2 = int(max(0, min(y2, orig_h - 1)))\n",
    "\n",
    "        label = f\"{CLASS_NAMES.get(cls,'Unknown')} {conf:.2f}\"\n",
    "\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "        cv2.putText(frame, label,\n",
    "                    (x1, max(20,y1-5)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (0,255,0), 2)\n",
    "\n",
    "    if frame_detections > 0:\n",
    "        frames_with_detections += 1\n",
    "\n",
    "    writer.write(frame)\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "# ================= RESULTS =================\n",
    "if timings:\n",
    "    avg_time = sum(timings) / len(timings)\n",
    "    avg_fps = 1.0 / avg_time\n",
    "else:\n",
    "    avg_fps = 0.0\n",
    "\n",
    "print(\"\\n========== RESULTS ==========\")\n",
    "print(f\"Frames processed           : {frame_count}\")\n",
    "print(f\"Avg FPS (model)            : {avg_fps:.2f}\")\n",
    "print(f\"Output file                : {OUTPUT_VIDEO}\")\n",
    "print(f\"File size (MB)             : {os.path.getsize(OUTPUT_VIDEO)/1e6:.2f}\")\n",
    "\n",
    "print(\"\\n========== DETECTION STATS ==========\")\n",
    "print(f\"Total detections           : {total_detections}\")\n",
    "print(f\"Frames with detections     : {frames_with_detections}\")\n",
    "print(f\"Max confidence observed    : {max_conf_seen:.6f}\")\n",
    "print(\"======================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b47228a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂ Loading YOLOv26 INT8 model...\n",
      "\n",
      "========== RESULTS ==========\n",
      "Frames processed        : 301\n",
      "Avg FPS (model)         : 23.52\n",
      "Total detections        : 60\n",
      "Frames w/ detections    : 48\n",
      "Max confidence observed : 0.9579\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# ================= CONFIG =================\n",
    "TFLITE_MODEL = \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_full_integer_quant.tflite\"\n",
    "VIDEO_PATH = \"/home/saber/GitHub/road_anomaly_detection/data/videos/3695999-hd_1920_1080_24fps.mp4\"\n",
    "OUTPUT_VIDEO = \"../../../runs/tflite/output_predictions.avi\"\n",
    "\n",
    "MODEL_IMG_SIZE = 640\n",
    "CONF_THRESH = 0.01\n",
    "NUM_WARMUP = 20\n",
    "MAX_FRAMES = 300\n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: \"Road Defect\",\n",
    "    1: \"Pothole\"\n",
    "}\n",
    "\n",
    "# ================= LETTERBOX =================\n",
    "def letterbox(img, new_shape=640):\n",
    "    shape = img.shape[:2]\n",
    "    r = min(new_shape / shape[0], new_shape / shape[1])\n",
    "\n",
    "    new_unpad = (int(round(shape[1] * r)),\n",
    "                 int(round(shape[0] * r)))\n",
    "\n",
    "    img_resized = cv2.resize(img, new_unpad,\n",
    "                             interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    dw = new_shape - new_unpad[0]\n",
    "    dh = new_shape - new_unpad[1]\n",
    "    dw /= 2\n",
    "    dh /= 2\n",
    "\n",
    "    top = int(round(dh - 0.1))\n",
    "    bottom = int(round(dh + 0.1))\n",
    "    left = int(round(dw - 0.1))\n",
    "    right = int(round(dw + 0.1))\n",
    "\n",
    "    img_padded = cv2.copyMakeBorder(\n",
    "        img_resized,\n",
    "        top, bottom, left, right,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=(114, 114, 114)\n",
    "    )\n",
    "\n",
    "    return img_padded, r, dw, dh\n",
    "\n",
    "# ================= LOAD MODEL =================\n",
    "print(\"‚ñ∂ Loading YOLOv26 INT8 model...\")\n",
    "\n",
    "interpreter = tf.lite.Interpreter(\n",
    "    model_path=TFLITE_MODEL,\n",
    "    num_threads=4\n",
    ")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_scale, input_zero = input_details[0][\"quantization\"]\n",
    "output_scale, output_zero = output_details[0][\"quantization\"]\n",
    "\n",
    "# ================= VIDEO SETUP =================\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "assert cap.isOpened(), \"‚ùå Could not open video\"\n",
    "\n",
    "ret, first_frame = cap.read()\n",
    "assert ret, \"‚ùå Could not read first frame\"\n",
    "\n",
    "FRAME_H, FRAME_W = first_frame.shape[:2]\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if fps == 0 or np.isnan(fps):\n",
    "    fps = 24\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_VIDEO), exist_ok=True)\n",
    "\n",
    "writer = cv2.VideoWriter(\n",
    "    OUTPUT_VIDEO,\n",
    "    cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "    fps,\n",
    "    (FRAME_W, FRAME_H)\n",
    ")\n",
    "\n",
    "assert writer.isOpened(), \"‚ùå VideoWriter failed\"\n",
    "\n",
    "# ================= COUNTERS =================\n",
    "frame_count = 0\n",
    "timings = []\n",
    "total_detections = 0\n",
    "frames_with_detections = 0\n",
    "max_conf_seen = 0.0\n",
    "\n",
    "# ================= INFERENCE LOOP =================\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count > MAX_FRAMES:\n",
    "        break\n",
    "\n",
    "    orig_h, orig_w = frame.shape[:2]\n",
    "\n",
    "    # ---------- PREPROCESS ----------\n",
    "    img, r, dw, dh = letterbox(frame, MODEL_IMG_SIZE)\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "\n",
    "    img = img / input_scale + input_zero\n",
    "    img = np.clip(img, -128, 127).astype(np.int8)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], img)\n",
    "\n",
    "    # ---------- INFERENCE ----------\n",
    "    start = time.perf_counter()\n",
    "    interpreter.invoke()\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    if frame_count > NUM_WARMUP:\n",
    "        timings.append(end - start)\n",
    "\n",
    "    # ---------- POSTPROCESS ----------\n",
    "    output = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    output = (output.astype(np.float32) - output_zero) * output_scale\n",
    "    output = output[0]\n",
    "\n",
    "    frame_detections = 0\n",
    "\n",
    "    for det in output:\n",
    "        if len(det) < 6:\n",
    "            continue\n",
    "\n",
    "        cx, cy, w, h, conf, cls = det[:6]\n",
    "\n",
    "        if conf > max_conf_seen:\n",
    "            max_conf_seen = conf\n",
    "\n",
    "        if conf < CONF_THRESH:\n",
    "            continue\n",
    "\n",
    "        frame_detections += 1\n",
    "        total_detections += 1\n",
    "        cls = int(cls)\n",
    "\n",
    "        # Convert center ‚Üí corners\n",
    "        x1 = cx - w / 2\n",
    "        y1 = cy - h / 2\n",
    "        x2 = cx + w / 2\n",
    "        y2 = cy + h / 2\n",
    "\n",
    "        # Reverse letterbox\n",
    "        x1 = (x1 - dw) / r\n",
    "        y1 = (y1 - dh) / r\n",
    "        x2 = (x2 - dw) / r\n",
    "        y2 = (y2 - dh) / r\n",
    "\n",
    "        x1 = int(max(0, min(x1, orig_w - 1)))\n",
    "        y1 = int(max(0, min(y1, orig_h - 1)))\n",
    "        x2 = int(max(0, min(x2, orig_w - 1)))\n",
    "        y2 = int(max(0, min(y2, orig_h - 1)))\n",
    "\n",
    "        label = f\"{CLASS_NAMES.get(cls,'Unknown')} {conf:.2f}\"\n",
    "\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "        cv2.putText(frame, label,\n",
    "                    (x1, max(20,y1-5)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (0,255,0), 2)\n",
    "\n",
    "    if frame_detections > 0:\n",
    "        frames_with_detections += 1\n",
    "\n",
    "    writer.write(frame)\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "# ================= RESULTS =================\n",
    "avg_fps = 1.0 / (sum(timings) / len(timings)) if timings else 0.0\n",
    "\n",
    "print(\"\\n========== RESULTS ==========\")\n",
    "print(f\"Frames processed        : {frame_count}\")\n",
    "print(f\"Avg FPS (model)         : {avg_fps:.2f}\")\n",
    "print(f\"Total detections        : {total_detections}\")\n",
    "print(f\"Frames w/ detections    : {frames_with_detections}\")\n",
    "print(f\"Max confidence observed : {max_conf_seen:.4f}\")\n",
    "print(\"================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6127e779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "\n",
      "OUTPUT SHAPE: (300, 6)\n",
      "\n",
      "FIRST 5 RAW DETECTIONS:\n",
      "[0.         0.         0.04187488 0.0261718  0.         0.        ]\n",
      "[0.         0.         0.04187488 0.0261718  0.         0.99976283]\n",
      "[0.         0.         0.05757796 0.0261718  0.         0.        ]\n",
      "[0.         0.         0.05757796 0.0261718  0.         0.99976283]\n",
      "[0.         0.         0.07328104 0.0261718  0.         0.        ]\n",
      "\n",
      "COORD RANGE:\n",
      "x1 min/max: 0.0 0.9788254\n",
      "y1 min/max: 0.0 0.00523436\n",
      "x2 min/max: 0.04187488 0.99976283\n",
      "y2 min/max: 0.00523436 0.06804668\n",
      "\n",
      "CONF RANGE:\n",
      "min conf: 0.0\n",
      "max conf: 0.0\n",
      "\n",
      "Saved debug_frame.jpg with big red box.\n",
      "Open it and confirm red box appears.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "TFLITE_MODEL = \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_full_integer_quant.tflite\"\n",
    "VIDEO_PATH = \"/home/saber/GitHub/road_anomaly_detection/data/videos/3695999-hd_1920_1080_24fps.mp4\"\n",
    "\n",
    "MODEL_IMG_SIZE = 640\n",
    "CONF_THRESH = 0.01\n",
    "\n",
    "print(\"Loading model...\")\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_scale, input_zero = input_details[0][\"quantization\"]\n",
    "output_scale, output_zero = output_details[0][\"quantization\"]\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "ret, frame = cap.read()\n",
    "assert ret, \"Failed to read frame\"\n",
    "\n",
    "orig_h, orig_w = frame.shape[:2]\n",
    "\n",
    "# ---------------- PREPROCESS ----------------\n",
    "img = cv2.resize(frame, (MODEL_IMG_SIZE, MODEL_IMG_SIZE))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = img.astype(np.float32) / 255.0\n",
    "\n",
    "img = img / input_scale + input_zero\n",
    "img = np.clip(img, -128, 127).astype(np.int8)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "interpreter.set_tensor(input_details[0][\"index\"], img)\n",
    "interpreter.invoke()\n",
    "\n",
    "# ---------------- OUTPUT ----------------\n",
    "output = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "output = (output.astype(np.float32) - output_zero) * output_scale\n",
    "output = output[0]\n",
    "\n",
    "print(\"\\nOUTPUT SHAPE:\", output.shape)\n",
    "\n",
    "print(\"\\nFIRST 5 RAW DETECTIONS:\")\n",
    "for i in range(5):\n",
    "    print(output[i][:6])\n",
    "\n",
    "print(\"\\nCOORD RANGE:\")\n",
    "print(\"x1 min/max:\", np.min(output[:,0]), np.max(output[:,0]))\n",
    "print(\"y1 min/max:\", np.min(output[:,1]), np.max(output[:,1]))\n",
    "print(\"x2 min/max:\", np.min(output[:,2]), np.max(output[:,2]))\n",
    "print(\"y2 min/max:\", np.min(output[:,3]), np.max(output[:,3]))\n",
    "\n",
    "print(\"\\nCONF RANGE:\")\n",
    "print(\"min conf:\", np.min(output[:,4]))\n",
    "print(\"max conf:\", np.max(output[:,4]))\n",
    "\n",
    "# Draw a big red box to verify drawing works\n",
    "cv2.rectangle(frame, (100,100), (500,500), (0,0,255), 5)\n",
    "cv2.putText(frame, \"DEBUG BOX\", (100,90),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 3)\n",
    "\n",
    "cv2.imwrite(\"debug_frame.jpg\", frame)\n",
    "\n",
    "print(\"\\nSaved debug_frame.jpg with big red box.\")\n",
    "print(\"Open it and confirm red box appears.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7475a313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂ Loading YOLOv26 INT8 model...\n",
      "Input dtype : <class 'numpy.int8'>\n",
      "Output dtype: <class 'numpy.int8'>\n",
      "‚ñ∂ Resolution: 1920x1080, FPS: 24.0\n",
      "\n",
      "========== RESULTS ==========\n",
      "Frames processed        : 301\n",
      "Avg FPS (model)         : 23.24\n",
      "Total detections        : 6\n",
      "Frames w/ detections    : 5\n",
      "Max confidence observed : 0.8216\n",
      "Output file             : ../../../runs/tflite/output_predictions.avi\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# ================= CONFIG =================\n",
    "TFLITE_MODEL = \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_full_integer_quant.tflite\"\n",
    "VIDEO_PATH = \"/home/saber/GitHub/road_anomaly_detection/data/videos/3695999-hd_1920_1080_24fps.mp4\"\n",
    "OUTPUT_VIDEO = \"../../../runs/tflite/output_predictions.avi\"\n",
    "\n",
    "CONF_THRESH = 0.006\n",
    "NUM_WARMUP = 20\n",
    "MAX_FRAMES = 300\n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: \"Road Defect\",\n",
    "    1: \"Pothole\"\n",
    "}\n",
    "\n",
    "# ================= LOAD MODEL =================\n",
    "print(\"‚ñ∂ Loading YOLOv26 INT8 model...\")\n",
    "\n",
    "interpreter = tf.lite.Interpreter(\n",
    "    model_path=TFLITE_MODEL,\n",
    "    num_threads=4\n",
    ")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_scale, input_zero = input_details[0][\"quantization\"]\n",
    "output_scale, output_zero = output_details[0][\"quantization\"]\n",
    "\n",
    "print(\"Input dtype :\", input_details[0][\"dtype\"])\n",
    "print(\"Output dtype:\", output_details[0][\"dtype\"])\n",
    "\n",
    "# ================= VIDEO SETUP =================\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "assert cap.isOpened(), \"‚ùå Could not open video\"\n",
    "\n",
    "ret, first_frame = cap.read()\n",
    "assert ret, \"‚ùå Could not read first frame\"\n",
    "\n",
    "FRAME_H, FRAME_W = first_frame.shape[:2]\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if fps == 0 or np.isnan(fps):\n",
    "    fps = 24\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_VIDEO), exist_ok=True)\n",
    "\n",
    "writer = cv2.VideoWriter(\n",
    "    OUTPUT_VIDEO,\n",
    "    cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "    fps,\n",
    "    (FRAME_W, FRAME_H)\n",
    ")\n",
    "\n",
    "assert writer.isOpened(), \"‚ùå VideoWriter failed\"\n",
    "\n",
    "print(f\"‚ñ∂ Resolution: {FRAME_W}x{FRAME_H}, FPS: {fps}\")\n",
    "\n",
    "# ================= COUNTERS =================\n",
    "frame_count = 0\n",
    "timings = []\n",
    "total_detections = 0\n",
    "frames_with_detections = 0\n",
    "max_conf_seen = 0.0\n",
    "\n",
    "# ================= INFERENCE LOOP =================\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count > MAX_FRAMES:\n",
    "        break\n",
    "\n",
    "    orig_h, orig_w = frame.shape[:2]\n",
    "\n",
    "    # ---------- PREPROCESS ----------\n",
    "    img = cv2.resize(frame, (640, 640))  # model input size\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "\n",
    "    img = img / input_scale + input_zero\n",
    "    img = np.clip(img, -128, 127).astype(np.int8)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], img)\n",
    "\n",
    "    # ---------- INFERENCE ----------\n",
    "    start = time.perf_counter()\n",
    "    interpreter.invoke()\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    if frame_count > NUM_WARMUP:\n",
    "        timings.append(end - start)\n",
    "\n",
    "    # ---------- POSTPROCESS ----------\n",
    "    output = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    output = (output.astype(np.float32) - output_zero) * output_scale\n",
    "    output = output[0]\n",
    "\n",
    "    frame_detections = 0\n",
    "\n",
    "    for det in output:\n",
    "        if len(det) < 6:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2, obj, cls_conf = det\n",
    "\n",
    "        conf = cls_conf * obj # TRUE confidence\n",
    "\n",
    "        if conf > max_conf_seen:\n",
    "            max_conf_seen = conf\n",
    "\n",
    "        if conf < CONF_THRESH:\n",
    "            continue\n",
    "\n",
    "        frame_detections += 1\n",
    "        total_detections += 1\n",
    "\n",
    "        # Coordinates are normalized (0-1)\n",
    "        x1 = int(x1 * orig_w)\n",
    "        y1 = int(y1 * orig_h)\n",
    "        x2 = int(x2 * orig_w)\n",
    "        y2 = int(y2 * orig_h)\n",
    "\n",
    "        x1 = max(0, min(x1, orig_w - 1))\n",
    "        y1 = max(0, min(y1, orig_h - 1))\n",
    "        x2 = max(0, min(x2, orig_w - 1))\n",
    "        y2 = max(0, min(y2, orig_h - 1))\n",
    "\n",
    "        label = f\"Pothole {conf:.2f}\"\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label,\n",
    "                    (x1, max(20, y1 - 5)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (0, 255, 0), 2)\n",
    "\n",
    "    if frame_detections > 0:\n",
    "        frames_with_detections += 1\n",
    "\n",
    "    writer.write(frame)\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "# ================= RESULTS =================\n",
    "avg_fps = 1.0 / (sum(timings) / len(timings)) if timings else 0.0\n",
    "\n",
    "print(\"\\n========== RESULTS ==========\")\n",
    "print(f\"Frames processed        : {frame_count}\")\n",
    "print(f\"Avg FPS (model)         : {avg_fps:.2f}\")\n",
    "print(f\"Total detections        : {total_detections}\")\n",
    "print(f\"Frames w/ detections    : {frames_with_detections}\")\n",
    "print(f\"Max confidence observed : {max_conf_seen:.4f}\")\n",
    "print(f\"Output file             : {OUTPUT_VIDEO}\")\n",
    "print(\"================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e140aace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂ Loading YOLOv26 INT8 model...\n",
      "‚ñ∂ Resolution: 1920x1080, FPS: 24.0\n",
      "üé• Saving clip: ../../../runs/tflite/clips/detection_20260220_152133_t1.0s.avi\n",
      "‚úÖ Clip saved\n",
      "\n",
      "üé• Saving clip: ../../../runs/tflite/clips/detection_20260220_152140_t7.1s.avi\n",
      "‚úÖ Clip saved\n",
      "\n",
      "üé• Saving clip: ../../../runs/tflite/clips/detection_20260220_152147_t12.4s.avi\n",
      "\n",
      "========== RESULTS ==========\n",
      "Frames processed : 301\n",
      "Avg FPS          : 23.50\n",
      "Clips saved      : 3\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "\n",
    "# ================= CONFIG =================\n",
    "TFLITE_MODEL = \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_full_integer_quant.tflite\"\n",
    "VIDEO_PATH = \"/home/saber/GitHub/road_anomaly_detection/data/videos/3695999-hd_1920_1080_24fps.mp4\"\n",
    "OUTPUT_DIR = \"../../../runs/tflite/clips/\"\n",
    "\n",
    "CONF_THRESH = 0.01\n",
    "NUM_WARMUP = 20\n",
    "MAX_FRAMES = 300\n",
    "\n",
    "PRE_SECONDS = 2      # seconds before detection\n",
    "POST_SECONDS = 3     # seconds after detection\n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: \"Road Defect\",\n",
    "    1: \"Pothole\"\n",
    "}\n",
    "\n",
    "# ================= LOAD MODEL =================\n",
    "print(\"‚ñ∂ Loading YOLOv26 INT8 model...\")\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL, num_threads=4)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_scale, input_zero = input_details[0][\"quantization\"]\n",
    "output_scale, output_zero = output_details[0][\"quantization\"]\n",
    "\n",
    "# ================= VIDEO SETUP =================\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "assert cap.isOpened(), \"‚ùå Could not open video\"\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if fps == 0 or np.isnan(fps):\n",
    "    fps = 24\n",
    "\n",
    "FRAME_W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "FRAME_H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"‚ñ∂ Resolution: {FRAME_W}x{FRAME_H}, FPS: {fps}\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ================= BUFFER =================\n",
    "buffer_size = int(PRE_SECONDS * fps)\n",
    "frame_buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "post_frames_remaining = 0\n",
    "clip_writer = None\n",
    "clip_count = 0\n",
    "\n",
    "# ================= INFERENCE LOOP =================\n",
    "frame_count = 0\n",
    "timings = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count > MAX_FRAMES:\n",
    "        break\n",
    "\n",
    "    orig_frame = frame.copy()\n",
    "    frame_buffer.append(orig_frame)\n",
    "\n",
    "    orig_h, orig_w = frame.shape[:2]\n",
    "\n",
    "    # ---------- PREPROCESS ----------\n",
    "    img = cv2.resize(frame, (640, 640))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "\n",
    "    img = img / input_scale + input_zero\n",
    "    img = np.clip(img, -128, 127).astype(np.int8)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], img)\n",
    "\n",
    "    # ---------- INFERENCE ----------\n",
    "    start = time.perf_counter()\n",
    "    interpreter.invoke()\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    if frame_count > NUM_WARMUP:\n",
    "        timings.append(end - start)\n",
    "\n",
    "    # ---------- POSTPROCESS ----------\n",
    "    output = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    output = (output.astype(np.float32) - output_zero) * output_scale\n",
    "    output = output[0]\n",
    "\n",
    "    detection_this_frame = False\n",
    "\n",
    "    for det in output:\n",
    "        if len(det) < 6:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2, obj, cls_conf = det\n",
    "        conf = obj * cls_conf\n",
    "\n",
    "        if conf < CONF_THRESH:\n",
    "            continue\n",
    "\n",
    "        detection_this_frame = True\n",
    "\n",
    "        # Draw box (for saved clip)\n",
    "        x1 = int(x1 * orig_w)\n",
    "        y1 = int(y1 * orig_h)\n",
    "        x2 = int(x2 * orig_w)\n",
    "        y2 = int(y2 * orig_h)\n",
    "\n",
    "        cv2.rectangle(orig_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(orig_frame, f\"Pothole {conf:.2f}\",\n",
    "                    (x1, max(20, y1 - 5)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # ================= START CLIP IF DETECTED =================\n",
    "    if detection_this_frame and clip_writer is None:\n",
    "\n",
    "        timestamp_sec = frame_count / fps\n",
    "        readable_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        clip_filename = os.path.join(\n",
    "            OUTPUT_DIR,\n",
    "            f\"detection_{readable_time}_t{timestamp_sec:.1f}s.avi\"\n",
    "        )\n",
    "\n",
    "        clip_writer = cv2.VideoWriter(\n",
    "            clip_filename,\n",
    "            cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "            fps,\n",
    "            (FRAME_W, FRAME_H)\n",
    "        )\n",
    "\n",
    "        print(f\"üé• Saving clip: {clip_filename}\")\n",
    "\n",
    "        # Write buffered frames\n",
    "        for bf in frame_buffer:\n",
    "            clip_writer.write(bf)\n",
    "\n",
    "        post_frames_remaining = int(POST_SECONDS * fps)\n",
    "        clip_count += 1\n",
    "\n",
    "    # ================= CONTINUE WRITING POST FRAMES =================\n",
    "    if clip_writer is not None:\n",
    "        clip_writer.write(orig_frame)\n",
    "        post_frames_remaining -= 1\n",
    "\n",
    "        if post_frames_remaining <= 0:\n",
    "            clip_writer.release()\n",
    "            clip_writer = None\n",
    "            print(\"‚úÖ Clip saved\\n\")\n",
    "\n",
    "cap.release()\n",
    "\n",
    "avg_fps = 1.0 / (sum(timings) / len(timings)) if timings else 0.0\n",
    "\n",
    "print(\"\\n========== RESULTS ==========\")\n",
    "print(f\"Frames processed : {frame_count}\")\n",
    "print(f\"Avg FPS          : {avg_fps:.2f}\")\n",
    "print(f\"Clips saved      : {clip_count}\")\n",
    "print(\"================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e47b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5285ec09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f0492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59bff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂ Loading TFLite INT8 model...\n",
      "‚ñ∂ Saving output video: ../../../runs/tflite/output_predictions.avi\n",
      "‚ñ∂ Resolution: 1920x1080, FPS: 24.00\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 640 but expected 320 for dimension 1 of input 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     85\u001b[39m img = np.clip(img, \u001b[32m0\u001b[39m, \u001b[32m255\u001b[39m).astype(np.int8)\n\u001b[32m     86\u001b[39m img = np.expand_dims(img, axis=\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_details\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mindex\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m start = time.perf_counter()\n\u001b[32m     91\u001b[39m interpreter.invoke()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/road_anomaly_detection/.venv/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:764\u001b[39m, in \u001b[36mInterpreter.set_tensor\u001b[39m\u001b[34m(self, tensor_index, value)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, value):\n\u001b[32m    749\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[32m    750\u001b[39m \n\u001b[32m    751\u001b[39m \u001b[33;03m  Note this copies data in `value`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    762\u001b[39m \u001b[33;03m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[32m    763\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpreter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSetTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: Cannot set tensor: Dimension mismatch. Got 640 but expected 320 for dimension 1 of input 0."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# ================= CONFIG =================\n",
    "TFLITE_MODEL = \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class5/weights/best_saved_model/best_full_integer_quant.tflite\"\n",
    "VIDEO_PATH = \"/home/saber/GitHub/road_anomaly_detection/data/videos/3695999-hd_1920_1080_24fps.mp4\"\n",
    "OUTPUT_VIDEO = \"../../../runs/tflite/output_predictions.avi\"\n",
    "\n",
    "MODEL_IMG_SIZE = 640\n",
    "CONF_THRESH = 0.01\n",
    "NUM_WARMUP = 20\n",
    "MAX_FRAMES = 300\n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: \"Road Defect\",\n",
    "    1: \"Pothole\"\n",
    "}\n",
    "\n",
    "# ================= LOAD MODEL =================\n",
    "print(\"‚ñ∂ Loading TFLite INT8 model...\")\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "\n",
    "# ================= VIDEO SETUP =================\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "assert cap.isOpened(), \"‚ùå Could not open input video\"\n",
    "\n",
    "# Read first frame to get REAL resolution\n",
    "ret, first_frame = cap.read()\n",
    "assert ret, \"‚ùå Could not read first frame\"\n",
    "\n",
    "FRAME_H, FRAME_W = first_frame.shape[:2]\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Reset video to first frame\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# Create output directory if needed\n",
    "os.makedirs(os.path.dirname(OUTPUT_VIDEO), exist_ok=True)\n",
    "\n",
    "# Safe codec for Linux / Raspberry Pi\n",
    "writer = cv2.VideoWriter(\n",
    "    OUTPUT_VIDEO,\n",
    "    cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "    fps,\n",
    "    (FRAME_W, FRAME_H)\n",
    ")\n",
    "\n",
    "assert writer.isOpened(), \"‚ùå VideoWriter failed to open\"\n",
    "\n",
    "print(f\"‚ñ∂ Saving output video: {OUTPUT_VIDEO}\")\n",
    "print(f\"‚ñ∂ Resolution: {FRAME_W}x{FRAME_H}, FPS: {fps:.2f}\")\n",
    "\n",
    "# ================= INFERENCE LOOP =================\n",
    "frame_count = 0\n",
    "timings = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count > MAX_FRAMES:\n",
    "        break\n",
    "\n",
    "    orig_h, orig_w = frame.shape[:2]\n",
    "\n",
    "    # ---------- PREPROCESS ----------\n",
    "    img = cv2.resize(frame, (MODEL_IMG_SIZE, MODEL_IMG_SIZE))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "\n",
    "    # Quantize to INT8\n",
    "    img = img / input_scale + input_zero_point\n",
    "    img = np.clip(img, 0, 255).astype(np.int8)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], img)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    interpreter.invoke()\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    if frame_count > NUM_WARMUP:\n",
    "        timings.append(end - start)\n",
    "\n",
    "    # ---------- POSTPROCESS ----------\n",
    "    output = interpreter.get_tensor(output_details[0][\"index\"])[0]\n",
    "    output = output.transpose(1, 0)  # (8400, 6)\n",
    "\n",
    "    for det in output:\n",
    "        cx, cy, w, h, conf, cls = det\n",
    "\n",
    "        conf = conf / 255.0  # INT8 ‚Üí float\n",
    "        if conf < CONF_THRESH:\n",
    "            continue\n",
    "\n",
    "        cls = int(cls)\n",
    "\n",
    "        # Convert center ‚Üí corner\n",
    "        x1 = int((cx - w / 2) * orig_w / MODEL_IMG_SIZE)\n",
    "        y1 = int((cy - h / 2) * orig_h / MODEL_IMG_SIZE)\n",
    "        x2 = int((cx + w / 2) * orig_w / MODEL_IMG_SIZE)\n",
    "        y2 = int((cy + h / 2) * orig_h / MODEL_IMG_SIZE)\n",
    "\n",
    "        # Clamp to image bounds\n",
    "        x1 = max(0, min(x1, orig_w - 1))\n",
    "        y1 = max(0, min(y1, orig_h - 1))\n",
    "        x2 = max(0, min(x2, orig_w - 1))\n",
    "        y2 = max(0, min(y2, orig_h - 1))\n",
    "\n",
    "        label = f\"{CLASS_NAMES.get(cls, 'Unknown')} {conf:.2f}\"\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            label,\n",
    "            (x1, max(20, y1 - 5)),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    # ---------- WRITE FRAME ----------\n",
    "    writer.write(frame)\n",
    "\n",
    "# ================= CLEANUP =================\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "# ================= RESULTS =================\n",
    "if timings:\n",
    "    avg_time = sum(timings) / len(timings)\n",
    "    avg_fps = 1.0 / avg_time\n",
    "else:\n",
    "    avg_fps = 0.0\n",
    "\n",
    "print(\"\\n========== RESULTS ==========\")\n",
    "print(f\"Frames processed : {frame_count}\")\n",
    "print(f\"Avg FPS (model)  : {avg_fps:.2f}\")\n",
    "print(f\"Output file     : {OUTPUT_VIDEO}\")\n",
    "print(f\"File size       : {os.path.getsize(OUTPUT_VIDEO) / 1e6:.2f} MB\")\n",
    "print(\"================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bed8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee3f7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂ Testing video: 3695999-hd_1920_1080_24fps.mp4\n",
      "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.5.1+cu121 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 1\nos.environ['CUDA_VISIBLE_DEVICES']: -1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m model = YOLO(MODEL_PATH)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# ‚úÖ Correct YOLO video inference\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mVIDEO_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43miou\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIOU\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_ROOT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVIDEO_PATH\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# -------- VERIFY (robust) --------\u001b[39;00m\n\u001b[32m     36\u001b[39m out_dir = OUTPUT_ROOT / VIDEO_PATH.stem\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/road_anomaly_detection/.venv/lib/python3.12/site-packages/ultralytics/engine/model.py:529\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.args.device != args.get(\u001b[33m\"\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.predictor.args.device):\n\u001b[32m    528\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor = (predictor \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._smart_load(\u001b[33m\"\u001b[39m\u001b[33mpredictor\u001b[39m\u001b[33m\"\u001b[39m))(overrides=args, _callbacks=\u001b[38;5;28mself\u001b[39m.callbacks)\n\u001b[32m--> \u001b[39m\u001b[32m529\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_cli\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# only update args if predictor is already setup\u001b[39;00m\n\u001b[32m    531\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.args = get_cfg(\u001b[38;5;28mself\u001b[39m.predictor.args, args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/road_anomaly_detection/.venv/lib/python3.12/site-packages/ultralytics/engine/predictor.py:397\u001b[39m, in \u001b[36mBasePredictor.setup_model\u001b[39m\u001b[34m(self, model, verbose)\u001b[39m\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model.end2end:\n\u001b[32m    394\u001b[39m         model.set_head_attr(max_det=\u001b[38;5;28mself\u001b[39m.args.max_det, agnostic_nms=\u001b[38;5;28mself\u001b[39m.args.agnostic_nms)\n\u001b[32m    395\u001b[39m \u001b[38;5;28mself\u001b[39m.model = AutoBackend(\n\u001b[32m    396\u001b[39m     model=model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.model,\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m     device=\u001b[43mselect_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    398\u001b[39m     dnn=\u001b[38;5;28mself\u001b[39m.args.dnn,\n\u001b[32m    399\u001b[39m     data=\u001b[38;5;28mself\u001b[39m.args.data,\n\u001b[32m    400\u001b[39m     fp16=\u001b[38;5;28mself\u001b[39m.args.half,\n\u001b[32m    401\u001b[39m     fuse=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    402\u001b[39m     verbose=verbose,\n\u001b[32m    403\u001b[39m )\n\u001b[32m    405\u001b[39m \u001b[38;5;28mself\u001b[39m.device = \u001b[38;5;28mself\u001b[39m.model.device  \u001b[38;5;66;03m# update device\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[38;5;28mself\u001b[39m.args.half = \u001b[38;5;28mself\u001b[39m.model.fp16  \u001b[38;5;66;03m# update half\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/road_anomaly_detection/.venv/lib/python3.12/site-packages/ultralytics/utils/torch_utils.py:200\u001b[39m, in \u001b[36mselect_device\u001b[39m\u001b[34m(device, newline, verbose)\u001b[39m\n\u001b[32m    193\u001b[39m         LOGGER.info(s)\n\u001b[32m    194\u001b[39m         install = (\n\u001b[32m    195\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    196\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCUDA devices are seen by torch.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    197\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.device_count() == \u001b[32m0\u001b[39m\n\u001b[32m    198\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    199\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid CUDA \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevice=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m requested.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Use \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevice=cpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or pass valid CUDA device(s) if available,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m i.e. \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevice=0\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevice=0,1,2,3\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for Multi-GPU.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mtorch.cuda.is_available(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.cuda.is_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mtorch.cuda.device_count(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.cuda.device_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mos.environ[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvisible\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstall\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m         )\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cpu \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mps \u001b[38;5;129;01mand\u001b[39;00m torch.cuda.is_available():  \u001b[38;5;66;03m# prefer GPU if available\u001b[39;00m\n\u001b[32m    211\u001b[39m     devices = device.split(\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# i.e. \"0,1\" -> [\"0\", \"1\"]\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 1\nos.environ['CUDA_VISIBLE_DEVICES']: -1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ================= CONFIG =================\n",
    "VIDEO_PATH = Path(\"../../../data/videos/3695999-hd_1920_1080_24fps.mp4\")\n",
    "MODEL_PATH = \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov26s2_rdd2022_2class4/weights/best_saved_model/best_int8.tflite\"\n",
    "\n",
    "OUTPUT_ROOT = Path(\"/home/saber/GitHub/road_anomaly_detection/runs/rdd2022_finetuned/video_outputs\")\n",
    "\n",
    "IMG_SIZE = 640\n",
    "CONF = 0.25\n",
    "IOU = 0.7\n",
    "DEVICE = 0\n",
    "# =========================================\n",
    "\n",
    "print(f\"‚ñ∂ Testing video: {VIDEO_PATH.name}\")\n",
    "\n",
    "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# ‚úÖ Correct YOLO video inference\n",
    "model.predict(\n",
    "    source=str(VIDEO_PATH),\n",
    "    imgsz=IMG_SIZE,\n",
    "    conf=CONF,\n",
    "    iou=IOU,\n",
    "    device=DEVICE,\n",
    "    save=True,\n",
    "    project=str(OUTPUT_ROOT),\n",
    "    name=VIDEO_PATH.stem,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# -------- VERIFY (robust) --------\n",
    "out_dir = OUTPUT_ROOT / VIDEO_PATH.stem\n",
    "videos = list(out_dir.glob(\"*.mp4\")) + list(out_dir.glob(\"*.avi\"))\n",
    "\n",
    "print(\"\\n--- RESULT ---\")\n",
    "print(\"Output directory:\", out_dir)\n",
    "print(\"Videos found:\", videos)\n",
    "\n",
    "if videos:\n",
    "    print(\"üé• Annotated video saved at:\", videos[0])\n",
    "else:\n",
    "    print(\"‚ùå No video file found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469573d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc40b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.5.1+cu121 CPU (13th Gen Intel Core i7-13620H)\n",
      "Model summary (fused): 73 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (21.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=/home/saber/GitHub/road_anomaly_detection/data/calibr_yaml/data.yaml'\n",
      "Fast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 551.7¬±1075.8 MB/s, size: 78.3 KB)\n",
      "\u001b[KScanning /home/saber/GitHub/road_anomaly_detection/data/calibration_images.cache... 0 images, 300 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 300/300 18.2Mit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è Labels are missing or empty in /home/saber/GitHub/road_anomaly_detection/data/calibration_images.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.84...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.6s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best.onnx' (42.8 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.8...\n",
      "Saved artifact at '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serving_default'\n",
      "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(1, 6, 8400), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140077474479184: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140077474478608: TensorSpec(shape=(3, 3, 3, 32), dtype=tf.float32, name=None)\n",
      "  140074662350288: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140074662346832: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140074662351056: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
      "  140074662351440: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074662351248: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140074662350672: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074662351824: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074662350096: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074662353552: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140074662353744: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140074662350480: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140074662350864: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140074662351632: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074662352016: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074662353936: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
      "  140074662352592: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074662354320: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140074662352976: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
      "  140074662354128: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074662354512: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074662354704: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074662355280: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074662355088: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074662357200: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140074662357392: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074662354896: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140074662353168: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074662356624: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140074662357584: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074662356240: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140074662357968: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074662355472: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074662355664: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074662358352: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  140074662357776: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074662358544: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140074662356816: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
      "  140074662358160: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140074662358928: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  140074662359120: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140074662359696: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074662359504: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074662361616: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074662361808: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074662359312: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074662358736: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074662361040: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074662362000: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074662360656: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074662362384: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074662359888: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074662360080: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074662362768: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
      "  140074662362192: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140074662362576: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140074662361232: TensorSpec(shape=(3, 3, 256, 512), dtype=tf.float32, name=None)\n",
      "  140074662362960: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  140074323673168: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
      "  140074323673552: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  140074323674128: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323673936: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323676048: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  140074323676240: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140074323673744: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  140074323673360: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140074323674320: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323674512: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323676432: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
      "  140074323675088: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  140074323675472: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
      "  140074323676816: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140074323677008: TensorSpec(shape=(1, 1, 1024, 512), dtype=tf.float32, name=None)\n",
      "  140074323676624: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  140074323677584: TensorSpec(shape=(1, 1, 768, 256), dtype=tf.float32, name=None)\n",
      "  140074323675664: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140074323677968: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323677776: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323679888: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074323680080: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074323677392: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074323677200: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074323678160: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323678352: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323680464: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  140074323680272: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140074323679504: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
      "  140074323679312: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074323681040: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323680848: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323682960: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140074323683152: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074323680656: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140074323678928: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074323681232: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323681424: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323683536: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  140074323683344: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074323683728: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140074323682384: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074323682000: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074323685648: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  140074323685072: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140074323686608: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323686224: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323689296: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074323689104: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074323688912: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074323686992: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074323687184: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323687376: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074323688336: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  140074323688528: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140074323687952: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140074323686800: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  140074319642896: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140074319644816: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
      "  140074319644240: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  140074319645776: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074319645392: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074319645968: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  140074319648080: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140074319647504: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  140074319648848: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140074319646352: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074319646544: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140074319649232: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
      "  140074319649040: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  140074319647120: TensorSpec(shape=(3, 3, 512, 64), dtype=tf.float32, name=None)\n",
      "  140074319643280: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
      "  140074323684112: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
      "  140074319648272: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074319643088: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074323683920: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074319648464: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140074319643472: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140074323684304: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140074319649616: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074319643856: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074323684688: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074319650000: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140074319645200: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140074323686032: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140074319650384: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074319644624: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074323685456: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140074319647696: TensorSpec(shape=(3, 3, 512, 128), dtype=tf.float32, name=None)\n",
      "  140074319643664: TensorSpec(shape=(3, 3, 256, 128), dtype=tf.float32, name=None)\n",
      "  140074323684496: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074319648656: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074319642704: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074323682576: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074319649808: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074319644432: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074323685264: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140074319649424: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074319644048: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074323684880: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140074319651920: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
      "  140074319650576: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
      "  140074319645584: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
      "  140074323686416: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
      "  140074319650192: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  140074319645008: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  140074323685840: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  140074319650768: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140074319651152: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140074319651728: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140074319652112: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140074319653264: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
      "  140074319650960: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1770716127.860641   26428 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1770716127.861711   26428 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1770716128.465590   26428 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770716128.465873   26428 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1770716129.199016   26428 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1770716129.199101   26428 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1770716129.721904   26428 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770716129.721916   26428 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1770716130.300238   26428 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1770716130.300323   26428 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1770716130.726125   26428 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770716130.726136   26428 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1770716144.566175   26428 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770716144.566225   26428 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "W0000 00:00:1770716859.713725   26428 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770716859.713764   26428 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "W0000 00:00:1770717337.925271   26428 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770717337.925282   26428 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "W0000 00:00:1770717957.606567   26428 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770717957.606578   26428 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 2674.3s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model' (139.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ‚úÖ 0.0s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model/best_int8.tflite' (11.0 MB)\n",
      "\n",
      "Export complete (2674.6s)\n",
      "Results saved to \u001b[1m/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model/best_int8.tflite imgsz=640 int8\n",
      "Validate:        yolo val task=detect model=/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model/best_int8.tflite imgsz=640 data=../../../data/rdd2class_yolo/rdd2class.yaml int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model/best_int8.tflite'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best.pt\")\n",
    "\n",
    "model.export(\n",
    "    format=\"tflite\",\n",
    "    int8=True,\n",
    "    data=\"/home/saber/GitHub/road_anomaly_detection/data/calibr_yaml/data.yaml\",   # important\n",
    "    imgsz=640\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c1375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1770800845.712370    4396 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1770800845.733134    4396 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1770800845.865469    4396 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770800845.865538    4396 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770800845.865542    4396 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770800845.865552    4396 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model/best_int8.tflite for TensorFlow Lite inference...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saber/GitHub/road_anomaly_detection/.venv/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/saber/GitHub/road_anomaly_detection/data/potholes_cracks/cracks-and-potholes-in-road/ds0/img/765228_ES_259_259ES000000_00240_RAW.jpg: 640x640 3 cracks, 295.2ms\n",
      "Speed: 15.1ms preprocess, 295.2ms inference, 29.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m/home/saber/GitHub/road_anomaly_detection/runs/detect/predict6\u001b[0m\n",
      "Detections: 3\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\n",
    "    \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model/best_int8.tflite\"\n",
    ")\n",
    "\n",
    "results = model.predict(\n",
    "    source=\"/home/saber/GitHub/road_anomaly_detection/data/potholes_cracks/cracks-and-potholes-in-road/ds0/img/765228_ES_259_259ES000000_00240_RAW.jpg\",  # üëà start with 1 image\n",
    "    imgsz=640,\n",
    "    conf=0.05,      # low for INT8\n",
    "    iou=0.6,\n",
    "    device=\"cpu\",\n",
    "    save=True,\n",
    "    show=False\n",
    ")\n",
    "\n",
    "print(\"Detections:\", len(results[0].boxes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f4704a",
   "metadata": {},
   "source": [
    "# Reduced Resolution for PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eefbe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.5.1+cu121 CPU (13th Gen Intel Core i7-13620H)\n",
      "Model summary (fused): 73 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 6, 2100) (21.5 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1770980876.892542    8816 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1770980876.904255    8816 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1770980877.000886    8816 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770980877.000899    8816 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770980877.000900    8816 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770980877.000901    8816 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=/home/saber/GitHub/road_anomaly_detection/data/calibr_yaml/data.yaml'\n",
      "Fast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 383.2¬±89.8 MB/s, size: 97.6 KB)\n",
      "\u001b[KScanning /home/saber/GitHub/road_anomaly_detection/data/calibration_images.cache... 0 images, 300 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 300/300 96.8Mit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è Labels are missing or empty in /home/saber/GitHub/road_anomaly_detection/data/calibration_images.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.84...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.6s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best.onnx' (42.6 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.8...\n",
      "Saved artifact at '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serving_default'\n",
      "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 320, 320, 3), dtype=tf.float32, name='images')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(1, 6, 2100), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140533928944720: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140533928947984: TensorSpec(shape=(3, 3, 3, 32), dtype=tf.float32, name=None)\n",
      "  140533928944336: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140533905736720: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140533928950672: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
      "  140533905736144: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533905735760: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533905736912: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533905737680: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905737488: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533928945872: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140533928945488: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140533905739024: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140533905738832: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140533905737104: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905737872: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905738256: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
      "  140533905738448: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533905739216: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140533905739600: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
      "  140533905739984: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905740368: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533905740560: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905741136: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905740944: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905743056: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533905743248: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533905740752: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533905740176: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533905742480: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533905743440: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533905742096: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533905743824: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533905741328: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905741520: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905744208: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  140533905743632: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905744400: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140533905742672: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
      "  140533905744016: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533905744784: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  140533905744976: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533905745552: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905745360: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905747472: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533905747664: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905745168: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533905744592: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905746896: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533905747856: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905746512: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533905748240: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905745744: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905745936: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905748624: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
      "  140533905748048: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533905748816: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140533905747088: TensorSpec(shape=(3, 3, 256, 512), dtype=tf.float32, name=None)\n",
      "  140533905748432: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  140533905749200: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
      "  140533905749392: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  140533905749968: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905749776: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905751888: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  140533905751696: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533928945296: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  140533928947408: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533905750160: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905750352: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533928947600: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
      "  140533941978896: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  140533941980240: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
      "  140533941978704: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533941979088: TensorSpec(shape=(1, 1, 1024, 512), dtype=tf.float32, name=None)\n",
      "  140533941979664: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  140533941977360: TensorSpec(shape=(1, 1, 768, 256), dtype=tf.float32, name=None)\n",
      "  140533941978320: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533905751504: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905751312: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533967485840: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533941979472: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905749584: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533941979280: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905750928: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905749008: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533941978512: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  140533819540688: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533819541264: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
      "  140533819541072: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533819541648: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533819541456: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533819543568: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533819543760: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533819540880: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533819540112: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533819541840: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533819542032: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533819544144: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  140533819543952: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533819544336: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140533819542992: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533819542608: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533819546256: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  140533819545680: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533819547216: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533819546832: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533819547408: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533819548944: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533819549904: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533819550288: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533819547792: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533819547984: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533819549520: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  140533819548560: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533819547600: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140533819550096: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  140533819549136: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533819552208: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
      "  140533819551632: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  140533819553168: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533819552784: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533819553360: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  140533819555472: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533819554896: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  140533819555280: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533819553744: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533819553936: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533819555664: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
      "  140533819555088: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  140533819554512: TensorSpec(shape=(3, 3, 512, 64), dtype=tf.float32, name=None)\n",
      "  140533819550480: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
      "  140533819544720: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
      "  140533819553552: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533819549712: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533819544528: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533942600528: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533819550864: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533819544912: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533942600912: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533819551248: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533819545296: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533942601296: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533819552592: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533819546640: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533942601680: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533819552016: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533819546064: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533942600144: TensorSpec(shape=(3, 3, 512, 128), dtype=tf.float32, name=None)\n",
      "  140533819551056: TensorSpec(shape=(3, 3, 256, 128), dtype=tf.float32, name=None)\n",
      "  140533819545104: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533942599952: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533819550672: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533819543184: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533942601104: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533819551824: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533819545872: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533942600720: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533819551440: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533819545488: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533942603408: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
      "  140533942601872: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
      "  140533819552976: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
      "  140533819547024: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
      "  140533942601488: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  140533819552400: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  140533819546448: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  140533942602064: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140533942602448: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140533942603024: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140533942603216: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140533942604560: TensorSpec(shape=(1, 2, 2100), dtype=tf.float32, name=None)\n",
      "  140533942602256: TensorSpec(shape=(1, 2, 2100), dtype=tf.float32, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1770980885.919372    8816 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1770980885.919464    8816 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1770980886.480018    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770980886.480031    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1770980887.150256    8816 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1770980887.150326    8816 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1770980887.613513    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770980887.613527    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1770980888.170442    8816 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1770980888.170506    8816 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1770980888.735571    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770980888.735585    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1770980890.233234    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770980890.233247    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1770980890.262617    8816 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "W0000 00:00:1770980973.371913    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770980973.371923    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "W0000 00:00:1770981054.738837    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770981054.738850    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "W0000 00:00:1770981215.420615    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770981215.420627    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 499.9s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model' (139.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ‚úÖ 0.0s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model/best_int8.tflite' (10.9 MB)\n",
      "\n",
      "Export complete (500.1s)\n",
      "Results saved to \u001b[1m/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model/best_int8.tflite imgsz=320 int8\n",
      "Validate:        yolo val task=detect model=/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model/best_int8.tflite imgsz=320 data=../../../data/rdd2class_yolo/rdd2class.yaml int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model/best_int8.tflite'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best.pt\")\n",
    "\n",
    "model.export(\n",
    "    format=\"tflite\",\n",
    "    int8=True,\n",
    "    data=\"/home/saber/GitHub/road_anomaly_detection/data/calibr_yaml/data.yaml\",\n",
    "    imgsz=320\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93176e4",
   "metadata": {},
   "source": [
    "# Nano Model With low img size for PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c53505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.5.1+cu121 CPU (13th Gen Intel Core i7-13620H)\n",
      "Model summary (fused): 73 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best.pt' with input shape (1, 3, 256, 256) BCHW and output shape(s) (1, 6, 1344) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=/home/saber/GitHub/road_anomaly_detection/data/calibr_yaml/data.yaml'\n",
      "Fast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 418.5¬±145.6 MB/s, size: 130.0 KB)\n",
      "\u001b[KScanning /home/saber/GitHub/road_anomaly_detection/data/calibration_images.cache... 0 images, 300 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 300/300 6.1Mit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è Labels are missing or empty in /home/saber/GitHub/road_anomaly_detection/data/calibration_images.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.84...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.6s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best.onnx' (11.6 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.8...\n",
      "Saved artifact at '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best_saved_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serving_default'\n",
      "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 256, 256, 3), dtype=tf.float32, name='images')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(1, 6, 1344), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140533940151184: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140533940152144: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
      "  140533940152912: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  140533940154064: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140533940153872: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
      "  140533940152336: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140533940154640: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
      "  140533940153296: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140533940152720: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533940153104: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533940156560: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
      "  140533940156752: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  140533940154448: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
      "  140533940154256: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  140533940154832: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533940155024: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533940156944: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n",
      "  140533940155600: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140533940157712: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140533940155984: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
      "  140533940157136: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533940157328: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533940149264: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533942606288: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533942606864: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533942605712: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140533940158288: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140533940149648: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140533940156176: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140534091106448: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140534091105872: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140534091106640: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140534091105488: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140533942600336: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533942605136: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091106832: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  140534091105680: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534091105104: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140534091107408: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
      "  140534091104912: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534091106064: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  140534091107792: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534091107024: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091106256: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091109712: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534091109904: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534091107216: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534091107600: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534091109136: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534091110096: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534091108752: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534091110480: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534091107984: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091108176: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091110864: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  140534091110288: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534091111056: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140534091109328: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
      "  140534091110672: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140534091111440: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  140534091111632: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140534091112208: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091112016: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091114128: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140534091114320: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534091111824: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140534091111248: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534091112400: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091112592: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091114512: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  140534091113168: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140534091113552: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  140534091114896: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534091115088: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
      "  140534091114704: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140534091115664: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
      "  140534091113744: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534091116048: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091115856: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091117968: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534091118160: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534091115472: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534091115280: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534091116240: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091116432: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091118544: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  140534091118352: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534091117584: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
      "  140534091117392: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534091119120: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091118928: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091119696: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140534091119888: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140534091120080: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140534091118736: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140534091119312: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091119504: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534091120464: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
      "  140534091117008: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087189712: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140534087190096: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087190288: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087191632: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  140534087190672: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534087192592: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534087192208: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534087195472: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087194896: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087195088: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087195856: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087193168: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534087193360: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534087196048: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  140534087194320: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534087195664: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140534087193936: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140534087192976: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534087197584: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  140534087197008: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140534087198544: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534087198160: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534087201808: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140534087200848: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534087201232: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140534087202000: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534087199120: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534087199312: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534087200464: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  140534087198736: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140534087199888: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
      "  140534087192784: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
      "  140534087189520: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087201040: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087195280: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087190480: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087200272: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087196240: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087190864: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087202384: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087196624: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087191056: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087202768: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087197968: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087192016: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087203152: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087197392: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087191440: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087201616: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
      "  140534087196432: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
      "  140534087189328: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087201424: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087194512: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087189904: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087202576: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087197200: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087191248: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534087202192: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087196816: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087189136: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534087204304: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
      "  140534087203344: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
      "  140534087198352: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
      "  140534087192400: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
      "  140534087202960: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  140534087197776: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  140534087191824: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  140534087203536: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140534084387088: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140534087203920: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140534087204496: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140534087204688: TensorSpec(shape=(1, 2, 1344), dtype=tf.float32, name=None)\n",
      "  140534087198928: TensorSpec(shape=(1, 2, 1344), dtype=tf.float32, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1770997310.727062    8816 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1770997310.728091    8816 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1770997311.168501    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997311.168544    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1770997311.820358    8816 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1770997311.820428    8816 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1770997312.065845    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997312.065860    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1770997312.354467    8816 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1770997312.354559    8816 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1770997312.641594    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997312.641608    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1770997318.233138    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997318.233150    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "W0000 00:00:1770997347.759948    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997347.759960    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "W0000 00:00:1770997377.221616    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997377.221629    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "W0000 00:00:1770997435.118837    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997435.118848    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 204.6s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best_saved_model' (38.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ‚úÖ 0.0s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best_saved_model/best_int8.tflite' (3.0 MB)\n",
      "\n",
      "Export complete (204.7s)\n",
      "Results saved to \u001b[1m/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best_saved_model/best_int8.tflite imgsz=256 int8\n",
      "Validate:        yolo val task=detect model=/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best_saved_model/best_int8.tflite imgsz=256 data=/home/saber/GitHub/road_anomaly_detection/data/rdd2class_yolo/rdd2class.yaml int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best_saved_model/best_int8.tflite'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best.pt\")\n",
    "\n",
    "model.export(\n",
    "    format=\"tflite\",\n",
    "    int8=True,\n",
    "    data=\"/home/saber/GitHub/road_anomaly_detection/data/calibr_yaml/data.yaml\",\n",
    "    imgsz=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca840b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.5.1+cu121 CPU (13th Gen Intel Core i7-13620H)\n",
      "Model summary (fused): 73 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class5/weights/best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 6, 2100) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=/home/saber/GitHub/road_anomaly_detection/data/calibr_yaml/data.yaml'\n",
      "Fast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 300.6¬±67.7 MB/s, size: 65.2 KB)\n",
      "\u001b[KScanning /home/saber/GitHub/road_anomaly_detection/data/calibration_images.cache... 0 images, 300 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 300/300 179.8Mit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è Labels are missing or empty in /home/saber/GitHub/road_anomaly_detection/data/calibration_images.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.84...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.4s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class5/weights/best.onnx' (11.6 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.8...\n",
      "Saved artifact at '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class5/weights/best_saved_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serving_default'\n",
      "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 320, 320, 3), dtype=tf.float32, name='images')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(1, 6, 2100), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140534084389968: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140534084390160: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
      "  140534084387664: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  140534084391312: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140534084391120: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
      "  140534084389008: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140534084391888: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
      "  140534084390352: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140534084389584: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534084389776: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534084393808: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
      "  140534084394000: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  140534084391696: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
      "  140534084391504: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  140534084392080: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534084392272: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534084394192: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n",
      "  140534084392848: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140534084394576: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140534084393232: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
      "  140534084394384: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534084394768: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534084394960: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534084395536: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534084395344: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534084397456: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140534084397648: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140534084395152: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140534084393424: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140534084396880: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140534084397840: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140534084396496: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140534084398224: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140534084395728: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534084395920: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534084398608: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  140534084398032: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534084398800: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140534084397072: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
      "  140534084398416: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534084399184: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  140534084399376: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140534084399952: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534084399760: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534084402064: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534084401872: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534084399568: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534084398992: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534084401296: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534084402640: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534084400912: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140534084403024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140534084400144: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534084400336: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140534084401488: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  140533905745360: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905747472: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140533905738064: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
      "  140533905744976: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533905745168: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  140533905744592: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533905746512: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905747856: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905749392: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533905749968: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905746896: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533905747664: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905748240: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905745744: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905749776: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  140533905748048: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533905747088: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  140533905751696: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905750160: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
      "  140533905751888: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533905751312: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
      "  140533905748432: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905750928: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905749584: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905742864: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533905742288: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533905751504: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533905750352: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533905749008: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905750736: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905737296: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  140533905741712: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533905746128: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
      "  140533905746704: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533928951632: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533928945296: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533905739408: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140533905746320: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140533905738640: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  140533928946256: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  140533928944336: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533928947600: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533928946064: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
      "  140533928946448: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533928945680: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140533928945104: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533928951440: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533928947984: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  140533862498384: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533862499536: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533862499152: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533862502416: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533862501840: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533862502032: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533862502992: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533862500112: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533862500304: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533862502224: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  140533862502608: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533862501264: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  140533862500880: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533862499920: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533862504528: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  140533862503952: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533862505488: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533862505104: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533862505680: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533862507792: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533862507216: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  140533862508560: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  140533862506064: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533862506256: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  140533862508944: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  140533862508752: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  140533862506832: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
      "  140533862502800: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
      "  140533928946640: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533862507984: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533862499728: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533928947024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533862508176: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533862503184: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533928946832: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533862509328: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533862503568: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533928945488: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533862509712: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533862504912: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533862498960: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533862510096: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533862504336: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533862498576: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533862507408: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
      "  140533862503376: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
      "  140533928944720: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533862508368: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533862501456: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533928949712: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533862509520: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533862504144: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533928945872: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  140533862509136: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533862503760: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533928950672: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  140533862511632: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
      "  140533862510288: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
      "  140533862505296: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
      "  140533862499344: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
      "  140533862509904: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  140533862504720: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  140533862498768: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  140533862510480: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140533862510864: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140533862511440: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140533862511824: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  140533862512976: TensorSpec(shape=(1, 2, 2100), dtype=tf.float32, name=None)\n",
      "  140533862510672: TensorSpec(shape=(1, 2, 2100), dtype=tf.float32, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1770997510.556514    8816 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1770997510.558034    8816 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1770997510.873778    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997510.873791    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1770997511.217061    8816 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1770997511.217140    8816 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1770997511.468400    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997511.468415    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1770997512.040157    8816 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1770997512.040252    8816 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1770997512.290799    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997512.290815    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1770997518.613871    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997518.613889    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "W0000 00:00:1770997562.959582    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997562.959595    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "W0000 00:00:1770997606.847293    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997606.847307    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "W0000 00:00:1770997693.717921    8816 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770997693.717933    8816 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 287.2s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class5/weights/best_saved_model' (38.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ‚úÖ 0.0s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class5/weights/best_saved_model/best_int8.tflite' (3.0 MB)\n",
      "\n",
      "Export complete (287.3s)\n",
      "Results saved to \u001b[1m/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class5/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class5/weights/best_saved_model/best_int8.tflite imgsz=320 int8\n",
      "Validate:        yolo val task=detect model=/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class5/weights/best_saved_model/best_int8.tflite imgsz=320 data=/home/saber/GitHub/road_anomaly_detection/data/rdd2class_yolo/rdd2class.yaml int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class5/weights/best_saved_model/best_int8.tflite'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class5/weights/best.pt\")\n",
    "\n",
    "model.export(\n",
    "    format=\"tflite\",\n",
    "    int8=True,\n",
    "    data=\"/home/saber/GitHub/road_anomaly_detection/data/calibr_yaml/data.yaml\",\n",
    "    imgsz=320\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4228918",
   "metadata": {},
   "source": [
    "# Nano 250 with NMS True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c481b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.9 üöÄ Python-3.12.12 torch-2.5.1+cu121 CPU (13th Gen Intel Core i7-13620H)\n",
      "Model summary (fused): 73 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best.pt' with input shape (1, 3, 256, 256) BCHW and output shape(s) (1, 300, 6) (5.9 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1771046759.497222    9175 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1771046759.509117    9175 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1771046759.611176    9175 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771046759.611190    9175 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771046759.611191    9175 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771046759.611192    9175 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m collecting INT8 calibration images from 'data=/home/saber/GitHub/road_anomaly_detection/data/calibr_yaml/data.yaml'\n",
      "Fast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 442.2¬±116.4 MB/s, size: 129.8 KB)\n",
      "\u001b[KScanning /home/saber/GitHub/road_anomaly_detection/data/calibration_images.cache... 0 images, 300 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 300/300 96.8Mit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è Labels are missing or empty in /home/saber/GitHub/road_anomaly_detection/data/calibration_images.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.84...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.9s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best.onnx' (11.6 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.8...\n",
      "Saved artifact at '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best_saved_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serving_default'\n",
      "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 256, 256, 3), dtype=tf.float32, name='images')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(1, 300, 6), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  139754888418832: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139754888418256: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
      "  139754888419792: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  139754888422288: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139754888422864: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
      "  139754888416528: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139754888421904: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
      "  139754888423056: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139754888415568: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754888423632: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754888425168: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
      "  139754888424400: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  139754888423824: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
      "  139754888424976: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  139754888423248: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754888424016: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754888415952: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n",
      "  139754888424592: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139754888425360: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139754888425744: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
      "  139754888426128: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754888426512: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754888426704: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754888427280: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754888427088: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754888429200: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139754888428624: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139757490569872: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139754888426320: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139754888429392: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139754888426896: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139754888428816: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139754888428240: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139754888427472: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754888427664: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754888429008: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  139754864935376: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754864935952: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139754864935760: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
      "  139754864935568: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139754864937104: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  139754864936144: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139754864936336: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864936720: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864938832: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754864939024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754864935184: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754864936528: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754864938256: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754864939216: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754864937872: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754864939600: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754864936912: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864937296: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864939984: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  139754864939408: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139754864940176: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139754864938448: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
      "  139754864939792: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139754864940560: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  139754864940752: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139754864941328: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864941136: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864943248: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  139754864943440: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139754864940944: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  139754864940368: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139754864941520: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864941712: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864943632: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  139754864942288: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139754864942672: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  139754864944016: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139754864942864: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
      "  139754864943824: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139754864944784: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
      "  139754864944592: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139754864945168: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864944976: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864947088: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754864947280: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754864944208: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754864944400: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754864945360: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864945552: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864947664: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  139754864947472: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139754864946704: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
      "  139754864946512: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754864948240: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864948048: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864950160: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139754864949584: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139754864951120: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139754864949776: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139754864948432: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864948624: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754864950544: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
      "  139754864946128: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754864947856: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139754864950736: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754864950928: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815374928: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  139754815374352: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139754815375888: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754815375504: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754815378768: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754815378192: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815378384: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754815379152: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815376464: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754815376656: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754815379344: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  139754815377616: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139754815378960: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139754815377232: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  139754815376272: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139754815380880: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  139754815380304: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139754815381840: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754815381456: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754815385104: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  139754815384144: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139754815384528: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  139754815385296: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139754815382416: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754815382608: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  139754815383760: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  139754815382032: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139754815383184: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
      "  139754815376080: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
      "  139754864950352: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754815384336: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815378576: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754864949200: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815383568: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754815379536: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754815373776: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754815385680: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815379920: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815373968: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815386064: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754815381264: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754815375312: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754815386448: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815380688: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815374736: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815384912: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
      "  139754815379728: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
      "  139754815373392: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754815384720: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815377808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815373584: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815385872: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754815380496: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754815374544: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139754815385488: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815380112: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815374160: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139754815386640: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
      "  139754815381648: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
      "  139754815375696: TensorSpec(shape=(1, 1, 64, 2), dtype=tf.float32, name=None)\n",
      "  139754815388752: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
      "  139754815386256: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  139754815381072: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  139754815375120: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  139754815387216: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139754815387600: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139754815388176: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139754815382224: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139754815387984: TensorSpec(shape=(1, 2, 1344), dtype=tf.float32, name=None)\n",
      "  139754815389328: TensorSpec(shape=(1, 2, 1344), dtype=tf.float32, name=None)\n",
      "  139754083026512: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139754083026704: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139754083026320: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139754083025168: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139754083027664: TensorSpec(shape=(1344, 4), dtype=tf.int64, name=None)\n",
      "  139754083029584: TensorSpec(shape=(2,), dtype=tf.int64, name=None)\n",
      "  139754083028432: TensorSpec(shape=(2,), dtype=tf.int64, name=None)\n",
      "  139754083031696: TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      "  139754083030736: TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      "  139754083027280: TensorSpec(shape=(1,), dtype=tf.bool, name=None)\n",
      "  139754083029200: TensorSpec(shape=(1,), dtype=tf.int32, name=None)\n",
      "  139754083028816: TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      "  139754083031120: TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      "  139754083028048: TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      "  139754083028240: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
      "  139754083031312: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
      "  139754083025360: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139754083027088: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  139754083032272: TensorSpec(shape=(2, 2), dtype=tf.int32, name=None)\n",
      "  139754083032656: TensorSpec(shape=(), dtype=tf.int64, name=None)\n",
      "  139754083030928: TensorSpec(shape=(), dtype=tf.int64, name=None)\n",
      "  139754083032080: TensorSpec(shape=(1,), dtype=tf.int64, name=None)\n",
      "  139754083031504: TensorSpec(shape=(1,), dtype=tf.int64, name=None)\n",
      "  139754083032848: TensorSpec(shape=(1,), dtype=tf.int64, name=None)\n",
      "  139754083030544: TensorSpec(shape=(), dtype=tf.int64, name=None)\n",
      "  139754083031888: TensorSpec(shape=(1,), dtype=tf.int64, name=None)\n",
      "  139754083033616: TensorSpec(shape=(1,), dtype=tf.int64, name=None)\n",
      "  139754083033808: TensorSpec(shape=(1,), dtype=tf.int64, name=None)\n",
      "  139754083036496: TensorSpec(shape=(1, 300, 6), dtype=tf.float32, name=None)\n",
      "  139754083036112: TensorSpec(shape=(1, 1), dtype=tf.int64, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1771046769.701842    9175 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1771046769.701946    9175 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1771046770.080645    9175 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771046770.080658    9175 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1771046770.503488    9175 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1771046770.503563    9175 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1771046770.819838    9175 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771046770.819854    9175 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1771046771.112954    9175 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1771046771.113023    9175 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1771046771.426162    9175 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771046771.426177    9175 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1771046772.481552    9175 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771046772.481564    9175 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1771046772.501134    9175 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "W0000 00:00:1771046802.750716    9175 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771046802.750727    9175 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "W0000 00:00:1771046832.696351    9175 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771046832.696363    9175 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "W0000 00:00:1771046891.501857    9175 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1771046891.501867    9175 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 190.9s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best_saved_model' (38.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ‚úÖ 0.0s, saved as '/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best_saved_model/best_int8.tflite' (3.1 MB)\n",
      "\n",
      "Export complete (191.1s)\n",
      "Results saved to \u001b[1m/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best_saved_model/best_int8.tflite imgsz=256 int8\n",
      "Validate:        yolo val task=detect model=/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best_saved_model/best_int8.tflite imgsz=256 data=/home/saber/GitHub/road_anomaly_detection/data/rdd2class_yolo/rdd2class.yaml int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best_saved_model/best_int8.tflite'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best.pt\")\n",
    "\n",
    "model.export(\n",
    "    format=\"tflite\",\n",
    "    imgsz=256,\n",
    "    int8=True,\n",
    "    data=\"/home/saber/GitHub/road_anomaly_detection/data/calibr_yaml/data.yaml\",\n",
    "    nms=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2073a972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_images:0', 'index': 0, 'shape': array([  1, 256, 256,   3], dtype=int32), 'shape_signature': array([  1, 256, 256,   3], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003921568859368563, -128), 'quantization_parameters': {'scales': array([  0.0039216], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "model_path = Path(\"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8n8_rdd2022_2class_256/weights/best_saved_model/best_full_integer_quant.tflite\")\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=str(model_path))\n",
    "interpreter.allocate_tensors()\n",
    "print(interpreter.get_input_details())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cdf84b",
   "metadata": {},
   "source": [
    "# Infernece on Nano-256-NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74036a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1771323330.215045   69900 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1771323330.227322   69900 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1771323330.324661   69900 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771323330.324675   69900 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771323330.324675   69900 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771323330.324676   69900 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model/best_full_integer_quant.tflite for TensorFlow Lite inference...\n",
      "\n",
      "image 1/1 /home/saber/GitHub/road_anomaly_detection/data/potholes_cracks/cracks-and-potholes-in-road/ds0/img/765228_ES_259_259ES000000_00240_RAW.jpg: 320x320 3 cracks, 1 pothole, 24.4ms\n",
      "Speed: 8.4ms preprocess, 24.4ms inference, 13.9ms postprocess per image at shape (1, 3, 320, 320)\n",
      "Results saved to \u001b[1m/home/saber/GitHub/road_anomaly_detection/runs/detect/predict18\u001b[0m\n",
      "Detections: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saber/GitHub/road_anomaly_detection/.venv/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\n",
    "    \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_saved_model/best_full_integer_quant.tflite\"\n",
    ")\n",
    "\n",
    "results = model.predict(\n",
    "    source=\"/home/saber/GitHub/road_anomaly_detection/data/potholes_cracks/cracks-and-potholes-in-road/ds0/img/765228_ES_259_259ES000000_00240_RAW.jpg\",  # üëà start with 1 image\n",
    "    imgsz=640,\n",
    "    conf=0.25,      # low for INT8\n",
    "    iou=0.6,\n",
    "    device=\"cpu\",\n",
    "    save=True,\n",
    "    show=False\n",
    ")\n",
    "\n",
    "print(\"Detections:\", len(results[0].boxes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0faf29",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562110fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "road_anomaly_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
